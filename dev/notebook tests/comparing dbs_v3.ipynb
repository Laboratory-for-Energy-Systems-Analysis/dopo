{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from functions_v2 import*\n",
    "from methods import MethodFinder\n",
    "\n",
    "import brightway2 as bw\n",
    "import bw2data as bd\n",
    "import bw2analyzer as ba\n",
    "import bw2calc as bc\n",
    "\n",
    "#reduce?\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dopo\n",
    "import activity_filter\n",
    "from activity_filter import generate_sets_from_filters\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup up bw project and databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biosphere database already present!!! No setup is needed\n"
     ]
    }
   ],
   "source": [
    "bd.projects.set_current(\"premise-validation-try1\")\n",
    "bw.bw2setup()\n",
    "\n",
    "bio3=bw.Database('biosphere3')\n",
    "ei39=bw.Database('ecoinvent 3.9.1 cutoff')\n",
    "ei39SSP2=bw.Database('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup method dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method_1': {'object': Brightway2 Method: IPCC 2013: climate change: global warming potential (GWP100),\n",
       "  'method name': ('IPCC 2013',\n",
       "   'climate change',\n",
       "   'global warming potential (GWP100)'),\n",
       "  'short name': 'global warming potential (GWP100)',\n",
       "  'unit': 'kg CO2-Eq'},\n",
       " 'method_2': {'object': Brightway2 Method: EN15804: inventory indicators ISO21930: Cumulative Energy Demand - non-renewable energy resources,\n",
       "  'method name': ('EN15804',\n",
       "   'inventory indicators ISO21930',\n",
       "   'Cumulative Energy Demand - non-renewable energy resources'),\n",
       "  'short name': 'Cumulative Energy Demand - non-renewable energy resources',\n",
       "  'unit': 'megajoule'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Methods\n",
    "finder=MethodFinder()\n",
    "\n",
    "finder.find_and_create_method(criteria=['IPCC', '2013', 'GWP100'], exclude=['no LT'])\n",
    "finder.find_and_create_method(criteria=['EN15804','Cumulative', 'non-renewable' ])\n",
    "# finder.find_and_create_method(criteria=['land occupation','selected'])\n",
    "# finder.find_and_create_method(criteria=['EN15804','fresh water'])\n",
    "\n",
    "method_dict=finder.get_all_methods()\n",
    "method_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sectors & setup databse dictionaries containing sector activity lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cement = 'cement_small.yaml'\n",
    "electricity = 'electricity_small.yaml'\n",
    "fuels= 'fuels_small.yaml'\n",
    "steel = 'steel_small.yaml'\n",
    "transport = 'transport_small.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement': {'yaml': 'yamls\\\\cement_small.yaml', 'yaml identifier': 'Cement'},\n",
       " 'Steel': {'yaml': 'yamls\\\\steel_small.yaml', 'yaml identifier': 'Steel'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dict={}\n",
    "files_dict['Cement']={'yaml': 'yamls\\cement_small.yaml',\n",
    "                      'yaml identifier': 'Cement'}\n",
    "#files_dict['Electricity']= {'yaml':'yamls\\electricity_small.yaml',\n",
    "                            #'yaml identifier': 'Electricity'} #yaml identifier is the name of the filter in the yaml file, in the first line.\n",
    "files_dict['Steel']={'yaml':'yamls\\steel_small.yaml',\n",
    "                     'yaml identifier': 'Steel'}\n",
    "files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_yaml_files(files_dict, database):\n",
    "    '''\n",
    "    - Runs through the files_dict reading the defined filters in the yaml files.\n",
    "    - With another function a list that contains the filtered activities is created from the chosen database.\n",
    "    - This activity list is saved within the corresponding key (sector) in the dictionary main_dict which is based on the files_dict.\n",
    "\n",
    "    :param files_dict: dictionary of dictionaries. It should hold the yaml file path and the title in the first row of the yaml file. \n",
    "                        Like so: files_dict['Cement']={'yaml': 'yamls\\cement_small.yaml', 'yaml identifier': 'Cement'}\n",
    "    :param database: premise or ecoinvent database of choice.\n",
    "\n",
    "    It returns an updated dictionary which contains filtered activity lists for each sector.\n",
    "    '''\n",
    "\n",
    "    main_dict = copy.deepcopy(files_dict)\n",
    "\n",
    "    for key, value in main_dict.items():\n",
    "        yaml_file = value['yaml']\n",
    "        yaml_identifier = value['yaml identifier']\n",
    "        \n",
    "        #debug\n",
    "        print(f\"Processing {key} with database {database.name}\")\n",
    "        \n",
    "        # Generate the sector activities\n",
    "        sector_activities = generate_sets_from_filters(yaml_file, database)\n",
    "        \n",
    "        #debug\n",
    "        print(f\"Activities for {key}:\")\n",
    "        for activity in sector_activities[yaml_identifier]:\n",
    "            print(f\"  {activity.key}\")\n",
    "\n",
    "        # Convert the set of activities to a list\n",
    "        activities_list = list(sector_activities[yaml_identifier])\n",
    "        \n",
    "        # Add to the sectors_dict\n",
    "        main_dict[key]['activities'] = activities_list\n",
    "        \n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cement with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Cement:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '36a53c174f34e672bc15b7e55563685e')\n",
      "Processing Steel with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Steel:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'af6bd1221fc0206541fbaf481397bf0d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '18b0dcf01dd401e1549b3796e3786213')\n"
     ]
    }
   ],
   "source": [
    "premise_dict = process_yaml_files(files_dict=files_dict, database=ei39SSP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cement with database ecoinvent 3.9.1 cutoff\n",
      "Activities for Cement:\n",
      "  ('ecoinvent 3.9.1 cutoff', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "  ('ecoinvent 3.9.1 cutoff', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "  ('ecoinvent 3.9.1 cutoff', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ecoinvent 3.9.1 cutoff', '36a53c174f34e672bc15b7e55563685e')\n",
      "Processing Steel with database ecoinvent 3.9.1 cutoff\n",
      "Activities for Steel:\n",
      "  ('ecoinvent 3.9.1 cutoff', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "  ('ecoinvent 3.9.1 cutoff', '18b0dcf01dd401e1549b3796e3786213')\n",
      "  ('ecoinvent 3.9.1 cutoff', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'af6bd1221fc0206541fbaf481397bf0d')\n"
     ]
    }
   ],
   "source": [
    "eco_dict = process_yaml_files(files_dict=files_dict, database=ei39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_prem = [activity.key for activity in premise_dict['Cement']['activities']]\n",
    "keys_eco = [activity.key for activity in eco_dict['Cement']['activities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_prem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_eco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_dict['Cement']['activities'][0].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_dict['Cement']['activities'][0].key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate lca scores for each sectors activities, store them each in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def lca_scores_compare(database_dict, method_dict):\n",
    "    # Dictionary to store DataFrames for each sector\n",
    "    sector_dataframes = {}\n",
    "\n",
    "    # Labels for the DataFrame columns\n",
    "    labels = [\n",
    "        \"activity\",\n",
    "        \"activity key\",\n",
    "        \"reference product\",\n",
    "        \"location\",\n",
    "        \"method name\",\n",
    "        \"method unit\",\n",
    "        \"total\",\n",
    "    ]\n",
    "\n",
    "    # Loop through each sector in the database_dict\n",
    "    for sector, sector_data in database_dict.items():\n",
    "        # Initialize a dictionary to hold DataFrames for each method in the current sector\n",
    "        method_dataframes = {}\n",
    "\n",
    "        # Loop through each method in method_dict\n",
    "        for meth_key, meth_info in method_dict.items():\n",
    "            data = []  # Initialize a new list to hold data for the current method\n",
    "            \n",
    "            # Extract the 'method name' tuple from the current method info\n",
    "            method_name = meth_info['method name']\n",
    "            method_unit = meth_info['unit']\n",
    "\n",
    "            # Now loop through each activity in the sector\n",
    "            for act in sector_data['activities']:\n",
    "                # Ensure the activity is an instance of the expected class\n",
    "                if not isinstance(act, bd.backends.peewee.proxies.Activity):\n",
    "                    raise ValueError(\"`activities` must be an iterable of `Activity` instances\")\n",
    "                \n",
    "                # Perform LCA calculations\n",
    "                lca = bw.LCA({act: 1}, method_name)\n",
    "                lca.lci()\n",
    "                lca.lcia()\n",
    "                \n",
    "                # Collect data for the current activity and method\n",
    "                data.append([\n",
    "                    act[\"name\"],\n",
    "                    act.key,\n",
    "                    act.get(\"reference product\"),\n",
    "                    act.get(\"location\", \"\")[:25],\n",
    "                    method_name,\n",
    "                    method_unit,\n",
    "                    lca.score,\n",
    "                ])\n",
    "            \n",
    "            # Convert the data list to a DataFrame and store it in the sector's dictionary\n",
    "            method_dataframes[meth_key] = pd.DataFrame(data, columns=labels)\n",
    "\n",
    "        # Store the method_dataframes dictionary in the sector_dataframes dictionary\n",
    "        sector_dataframes[sector] = method_dataframes\n",
    "\n",
    "    # Now `sector_dataframes` is a dictionary where each key is a sector, and the value is another dictionary with method names and their corresponding DataFrames\n",
    "    return sector_dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecoinvent scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_scores=lca_scores_compare(eco_dict,method_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_scores['Cement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_scores['Cement']['method_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_scores['Steel']['method_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premise scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_scores=lca_scores_compare(premise_dict,method_dict) #dictionary containing sectors = keys and dataframes by method = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_scores['Steel']['method_1'] #what is happening here?, something wrong with sector!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def relative_changes_df(ecoinvent_scores, premise_scores):\n",
    "\n",
    "    dictionary = {}\n",
    "\n",
    "    # Iterate over sectors\n",
    "    for sector_key in ecoinvent_scores:\n",
    "        # Initialize the sector key in the output dictionary\n",
    "        if sector_key not in dictionary:\n",
    "            dictionary[sector_key] = {}\n",
    "\n",
    "        # Iterate over methods within the sector\n",
    "        for method_key in ecoinvent_scores[sector_key]:\n",
    "            # Check if the method_key exists in both dictionaries to avoid KeyError\n",
    "            if method_key in premise_scores.get(sector_key, {}):\n",
    "                # Get the corresponding DataFrames\n",
    "                df_ei = ecoinvent_scores[sector_key][method_key]\n",
    "                df_premise = premise_scores[sector_key][method_key]\n",
    "\n",
    "                #print(df_ei['activity key'])\n",
    "                #print(df_premise)\n",
    "\n",
    "                # Split the 'activity key' to extract the second part\n",
    "                df_ei['activity_code'] = df_ei['activity key'].apply(lambda x: x[1])  # Access the second element of the tuple\n",
    "                df_premise['activity_code'] = df_premise['activity key'].apply(lambda x: x[1])\n",
    "\n",
    "                # Merge the two dataframes based on the activity code and method name\n",
    "                merged_df = pd.merge(df_ei, df_premise, on=['activity_code', 'method name'], suffixes=('_ei', '_premise'))\n",
    "\n",
    "                # Calculate the relative change\n",
    "                merged_df['relative_change'] = ((merged_df['total_premise'] - merged_df['total_ei']) / merged_df['total_ei']) * 100\n",
    "\n",
    "                # Store the result in the dictionary\n",
    "                dictionary[sector_key][method_key] = merged_df\n",
    "\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_dict = relative_changes_df(eco_scores, premise_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_dict['Cement']['method_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method_1': {'rank': 16, 'relative_change': 14}, 'method_2': {'rank': 16, 'relative_change': 14}}\n"
     ]
    }
   ],
   "source": [
    "from dopo_excel import add_sector_marker\n",
    "\n",
    "# Prepare to save each LCA score table to a different worksheet in the same Excel file\n",
    "excel_file = 'compare_tables_v7.xlsx'\n",
    "column_positions = {} #stores the indexes of columns for plotting\n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "    for sector in relative_dict.keys():\n",
    "        relative_changes = relative_dict[sector]\n",
    "        \n",
    "        for method, table in relative_changes.items():\n",
    "            # Create a DataFrame for the current LCA score table\n",
    "            df = pd.DataFrame(table)\n",
    "\n",
    "            # Add sector marker\n",
    "            df = add_sector_marker(df, sector) #!! ADJUST POSITION            \n",
    "\n",
    "            # Sort the DataFrame by 'relative_change' from largest negative to largest positive\n",
    "            df = df.sort_values(by='relative_change', ascending=False)\n",
    "\n",
    "             # Add a 'rank' column based on the 'relative_change', ranking from most negative to least negative\n",
    "            df['rank'] = df['relative_change'].rank(ascending=False, method='dense').astype(int)\n",
    " \n",
    "            # Get the index values of columns\n",
    "            columns_of_interest = [\"rank\", \"relative_change\", \"method\", \"method unit\", ]\n",
    "            positions = {col: df.columns.get_loc(col) for col in columns_of_interest if col in df.columns}\n",
    "            column_positions[method] = positions\n",
    "\n",
    "            # Generate worksheet name\n",
    "            worksheet_name = f\"{sector}_{method}\"\n",
    "            if len(worksheet_name) > 31:\n",
    "                worksheet_name = worksheet_name[:31]\n",
    "\n",
    "            # Save the DataFrame to the Excel file in a new worksheet\n",
    "            df.to_excel(writer, sheet_name=worksheet_name, index=False)\n",
    "print(column_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "def categorize_sheets_by_sector(file_path):\n",
    "    # Load the workbook\n",
    "    workbook = load_workbook(filename=file_path, read_only=True)\n",
    "    \n",
    "    # Initialize a dictionary to hold sectors and their corresponding sheet names\n",
    "    worksheet_dict = {}\n",
    "    \n",
    "    # Iterate over all sheet names in the workbook\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        # Split the sheet name to extract the sector (assumes sector is the first part)\n",
    "        sector = sheet_name.split('_')[0]\n",
    "        \n",
    "        # Add the sheet name to the corresponding sector in the dictionary\n",
    "        if sector in worksheet_dict:\n",
    "            worksheet_dict[sector].append(sheet_name)\n",
    "        else:\n",
    "            worksheet_dict[sector] = [sheet_name]\n",
    "    \n",
    "    return worksheet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "def compare_database_charts(filename, worksheet_dict, index_positions=None):\n",
    "\n",
    "    # Load the workbook and select the sheet\n",
    "    wb = openpyxl.load_workbook(filename)\n",
    "\n",
    "    # Iterate over each sector and its associated worksheets\n",
    "    for sector, worksheet_names in worksheet_dict.items():\n",
    "        \n",
    "        # Create or get the chart sheet for the current sector\n",
    "        chart_sheet_name = f\"{sector}_charts\"\n",
    "        if chart_sheet_name in wb.sheetnames:\n",
    "            ws_charts = wb[chart_sheet_name]\n",
    "        else:\n",
    "            ws_charts = wb.create_sheet(chart_sheet_name)  \n",
    "        \n",
    "        # Initial position for the first chart\n",
    "        current_row = 1  # Start placing charts from row 1\n",
    "        current_col = 1  # Start placing charts from column 1\n",
    "        chart_height = 30  # Number of rows a chart occupies\n",
    "        chart_width = 12   # Number of columns a chart occupies\n",
    "        charts_per_row = 2  # Number of charts per row\n",
    "    \n",
    "        # Iterate over each worksheet name in the current sector\n",
    "        for i, worksheet_name in enumerate(worksheet_names):\n",
    "            ws = wb[worksheet_name]\n",
    "\n",
    "            # # Find the key in index_positions that contains worksheet_name\n",
    "            # matching_key = None\n",
    "            # for key in index_positions.keys():\n",
    "            #     if worksheet_name in key:\n",
    "            #         matching_key = key\n",
    "            #         break\n",
    "\n",
    "            # if not matching_key:\n",
    "            #     print(f\"Warning: No matching key found for worksheet '{worksheet_name}'. Skipping...\")\n",
    "            #     continue\n",
    "\n",
    "            # Retrieve the column positions from the index_positions dictionary\n",
    "            # positions = index_positions[matching_key]\n",
    "\n",
    "            # Find min_row, max_row and max_column\n",
    "            min_col_data = 15 #positions.get(\"relative_change\", None) + 1\n",
    "            rank_col = 17#positions.get(\"rank\", None) + 1\n",
    "            method_col = 5#positions.get(\"method\", None) + 1\n",
    "            method_unit_col = 6#positions.get(\"method unit\", None) + 1\n",
    "\n",
    "            # Create a bar chart\n",
    "            chart = BarChart()\n",
    "            chart.type=\"bar\"\n",
    "            chart.style=2\n",
    "            chart.overlap= 100\n",
    "            chart.title = \"Relative Change in LCA Scores\"\n",
    "            chart.x_axis.title = \"Activity\"\n",
    "            chart.y_axis.title = \"Relative Change (%)\"\n",
    "\n",
    "            # Set the data for the chart\n",
    "            data = Reference(ws, min_col=min_col_data, min_row=1, max_row=ws.max_row)\n",
    "            categories = Reference(ws, min_col=rank_col, min_row=2, max_row=ws.max_row)\n",
    "            chart.add_data(data, titles_from_data=True)\n",
    "            chart.set_categories(categories)\n",
    "\n",
    "            # Modify each series in the chart to disable the inversion of negative values \n",
    "            for series in chart.series:\n",
    "                series.invertIfNegative = False\n",
    "\n",
    "            # x-axis tickes\n",
    "            chart.x_axis.tickLblPos = \"low\"\n",
    "            chart.x_axis.majorGridlines = None \n",
    "            chart.x_axis.tickMarkSkip = 1  # Show all tick marks, this adresses the tick lines \n",
    "            chart.x_axis.tickLblSkip = 1  # Show all labels, doesnt work\n",
    "            chart.x_axis.delete = False  # Ensure axis is not deleted\n",
    "\n",
    "            # Chart titles\n",
    "            method_value = ws.cell(row=2, column=method_col).value\n",
    "            chart.title = f\"{sector} {method_value} database lca scores relative changes\"\n",
    "\n",
    "            method_unit_value = ws.cell(row=2, column=method_unit_col).value\n",
    "            chart.x_axis.title = f\"{method_unit_value}\"\n",
    "            \n",
    "            chart.y_axis.title = 'relative change (%)' #its switched..... should be x_axis\n",
    "\n",
    "            # Avoid overlap\n",
    "            chart.title.overlay = False\n",
    "            chart.x_axis.title.overlay = False\n",
    "            chart.y_axis.title.overlay = False \n",
    "            chart.legend.overlay = False\n",
    "\n",
    "            # Adjust chart dimensions\n",
    "            chart.width = 20  # Width of the chart\n",
    "            chart.height = 14  # Height of the chart\n",
    "\n",
    "            # Calculate the position for this chart\n",
    "            position = ws_charts.cell(row=current_row, column=current_col).coordinate\n",
    "            ws_charts.add_chart(chart, position)\n",
    "\n",
    "            # Update position for the next chart\n",
    "            current_col += chart_width +1 \n",
    "            if (i + 1) % charts_per_row == 0:  # Move to the next row after placing `charts_per_row` charts\n",
    "                current_row += chart_height +1\n",
    "                current_col = 1  # Reset to the first column\n",
    "\n",
    "        # Move the chart sheet to the first position\n",
    "        wb._sheets.remove(ws_charts)\n",
    "        wb._sheets.insert(0, ws_charts)\n",
    "\n",
    "            # Add the chart to a new worksheet\n",
    "            # new_sheet = wb.create_sheet(title=\"LCA Chart\")\n",
    "            # new_sheet.add_chart(chart, \"A1\")\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(filename)\n",
    "\n",
    "    print(f\"Results and chart saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement': ['Cement_method_1', 'Cement_method_2'],\n",
       " 'Steel': ['Steel_method_1', 'Steel_method_2'],\n",
       " 'LCA Chart': ['LCA Chart']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize_sheets_by_sector('compare_tables_v4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results and chart saved to compare_tables_v7.xlsx\n"
     ]
    }
   ],
   "source": [
    "compare_database_charts('compare_tables_v7.xlsx',categorize_sheets_by_sector('compare_tables_v7.xlsx')) #index_positions=column_positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "premise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
