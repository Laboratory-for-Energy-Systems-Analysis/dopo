{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import bw2data as bd\n",
    "import bw2analyzer as ba\n",
    "\n",
    "#reduce?\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dopo\n",
    "from dopo import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biosphere database already present!!! No setup is needed\n"
     ]
    }
   ],
   "source": [
    "bd.projects.set_current(\"premise-validation-try1\")\n",
    "bw.bw2setup()\n",
    "\n",
    "bio3=bw.Database('biosphere3')\n",
    "ei39=bw.Database('ecoinvent 3.9.1 cutoff')\n",
    "ei39SSP2=bw.Database('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sector filters file names/paths\n",
    "\n",
    "cement = 'cement_small.yaml'\n",
    "electricity = 'electricity_small.yaml'\n",
    "fuels= 'fuels_small.yaml'\n",
    "steel = 'steel_small.yaml'\n",
    "transport = 'transport_small.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement': {'yaml': 'yamls\\\\cement_small.yaml', 'yaml identifier': 'Cement'},\n",
       " 'Steel': {'yaml': 'yamls\\\\steel_small.yaml', 'yaml identifier': 'Steel'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dict={}\n",
    "files_dict['Cement']={'yaml': 'yamls\\cement_small.yaml', \n",
    "                      'yaml identifier': 'Cement'}\n",
    "files_dict['Steel']= {'yaml':'yamls\\steel_small.yaml',\n",
    "                            'yaml identifier': 'Steel'} #yaml identifier is the name of the filter in the yaml file, in the first line.\n",
    "files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cement with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Cement:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '36a53c174f34e672bc15b7e55563685e')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "Processing Steel with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Steel:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '18b0dcf01dd401e1549b3796e3786213')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'af6bd1221fc0206541fbaf481397bf0d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "Processing Cement with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Cement:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '36a53c174f34e672bc15b7e55563685e')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "Processing Steel with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Steel:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '18b0dcf01dd401e1549b3796e3786213')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'af6bd1221fc0206541fbaf481397bf0d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "Processing Cement with database ecoinvent 3.9.1 cutoff\n",
      "Activities for Cement:\n",
      "  ('ecoinvent 3.9.1 cutoff', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ecoinvent 3.9.1 cutoff', '36a53c174f34e672bc15b7e55563685e')\n",
      "  ('ecoinvent 3.9.1 cutoff', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "  ('ecoinvent 3.9.1 cutoff', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "Processing Steel with database ecoinvent 3.9.1 cutoff\n",
      "Activities for Steel:\n",
      "  ('ecoinvent 3.9.1 cutoff', 'af6bd1221fc0206541fbaf481397bf0d')\n",
      "  ('ecoinvent 3.9.1 cutoff', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "  ('ecoinvent 3.9.1 cutoff', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "  ('ecoinvent 3.9.1 cutoff', '18b0dcf01dd401e1549b3796e3786213')\n"
     ]
    }
   ],
   "source": [
    "import dopo.filter_sectors\n",
    "\n",
    "#for plot 1 and 2\n",
    "dictionary_one = dopo.filter_sectors.process_yaml_files(files_dict, ei39SSP2)\n",
    "\n",
    "#for comparison\n",
    "premise_dict = dopo.filter_sectors.process_yaml_files(files_dict, ei39SSP2)\n",
    "ecoinvent_dict = dopo.filter_sectors.process_yaml_files(files_dict, ei39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27',\n",
       " '86841f8c7ee2668f244d3b8e34f41932')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_one['Cement']['activities'][0].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method_1': {'object': Brightway2 Method: IPCC 2013: climate change: global warming potential (GWP100),\n",
       "  'method name': ('IPCC 2013',\n",
       "   'climate change',\n",
       "   'global warming potential (GWP100)'),\n",
       "  'short name': 'global warming potential (GWP100)',\n",
       "  'unit': 'kg CO2-Eq'},\n",
       " 'method_2': {'object': Brightway2 Method: EN15804: inventory indicators ISO21930: Cumulative Energy Demand - non-renewable energy resources,\n",
       "  'method name': ('EN15804',\n",
       "   'inventory indicators ISO21930',\n",
       "   'Cumulative Energy Demand - non-renewable energy resources'),\n",
       "  'short name': 'Cumulative Energy Demand - non-renewable energy resources',\n",
       "  'unit': 'megajoule'},\n",
       " 'method_3': {'object': Brightway2 Method: selected LCI results: resource: land occupation,\n",
       "  'method name': ('selected LCI results', 'resource', 'land occupation'),\n",
       "  'short name': 'land occupation',\n",
       "  'unit': 'square meter-year'},\n",
       " 'method_4': {'object': Brightway2 Method: EN15804: inventory indicators ISO21930: use of net fresh water,\n",
       "  'method name': ('EN15804',\n",
       "   'inventory indicators ISO21930',\n",
       "   'use of net fresh water'),\n",
       "  'short name': 'use of net fresh water',\n",
       "  'unit': 'cubic meter'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder=dopo.methods.MethodFinder()\n",
    "\n",
    "finder.find_and_create_method(criteria=['IPCC', '2013', 'GWP100'], exclude=['no LT'])\n",
    "finder.find_and_create_method(criteria=['EN15804','Cumulative', 'non-renewable' ])\n",
    "finder.find_and_create_method(criteria=['land occupation','selected'])\n",
    "finder.find_and_create_method(criteria=['EN15804','fresh water'])\n",
    "method_dict=finder.get_all_methods()\n",
    "method_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitting activity name common prefix: 'cement production, '\n",
      "Omitting activity name common prefix: 'cement production, '\n",
      "Omitting activity name common prefix: 'cement production, '\n",
      "Omitting activity name common prefix: 'cement production, '\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "Name: other, dtype: float64\n",
      "0    0.008358\n",
      "1    0.006612\n",
      "2    0.006691\n",
      "3    0.003714\n",
      "4    0.006260\n",
      "5    0.003002\n",
      "6    0.005879\n",
      "Name: other, dtype: float64\n",
      "[None]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "Name: other, dtype: float64\n",
      "0    0.083118\n",
      "1    0.109749\n",
      "2    0.272431\n",
      "3    0.141921\n",
      "4    0.114098\n",
      "5    0.104153\n",
      "6    0.292700\n",
      "Name: other, dtype: float64\n",
      "[None]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "Name: other, dtype: float64\n",
      "0    0.020712\n",
      "1    0.077349\n",
      "2    0.011369\n",
      "3    0.003362\n",
      "4    0.040139\n",
      "5    0.021213\n",
      "6    0.004656\n",
      "Name: other, dtype: float64\n",
      "[None]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "Name: other, dtype: float64\n",
      "0    0.001295\n",
      "1    0.000416\n",
      "2    0.000326\n",
      "3    0.000102\n",
      "4    0.001221\n",
      "5    0.000139\n",
      "6    0.000268\n",
      "Name: other, dtype: float64\n",
      "[None]\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "Name: other, dtype: float64\n",
      "0   -0.031801\n",
      "1   -0.004385\n",
      "2   -0.032627\n",
      "3    0.018912\n",
      "Name: other, dtype: float64\n",
      "[None]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "Name: other, dtype: float64\n",
      "0    0.342651\n",
      "1    0.360257\n",
      "2    0.390817\n",
      "3    1.127125\n",
      "Name: other, dtype: float64\n",
      "[None]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "Name: other, dtype: float64\n",
      "0    0.012999\n",
      "1    0.045640\n",
      "2    0.015952\n",
      "3    0.048418\n",
      "Name: other, dtype: float64\n",
      "[None]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "Name: other, dtype: float64\n",
      "0    0.000684\n",
      "1    0.000886\n",
      "2    0.000716\n",
      "3    0.001132\n",
      "Name: other, dtype: float64\n",
      "[None]\n"
     ]
    }
   ],
   "source": [
    "scores_dictionary_one = dopo.sector_lca_scores(dictionary_one, method_dict, cutoff=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_lca_scores(main_dict, method_dict, cutoff=0.02):\n",
    "    '''\n",
    "    Generates the LCA score tables for activity list of each sector.\n",
    "    The tables contain total scores and cpc input contributions.\n",
    "    This is done by each method defined in the method dictionary.\n",
    "\n",
    "    :param main_dict: dictionary which is returned by process_yaml_files function\n",
    "    :param method_dict: dictionary which is created with MethodFinder class\n",
    "    :param cutoff: cutoff value to summarize inputs below or equal to this threshhold in a \"other\" column\n",
    "\n",
    "    It returns the main dictionary updated as scores dictionary which also holds the former information for each sector.\n",
    "    The LCA scores are stored by method name in the respective sector dictionary within the main dictionary.\n",
    "    '''\n",
    "\n",
    "    # Initialize scores_dict as a copy of main_dict\n",
    "    scores_dict = main_dict.copy()\n",
    "\n",
    "    # Loop through each sector in main_dict\n",
    "    for sector in scores_dict.keys():\n",
    "        # Extract activities for the current sector\n",
    "        sector_activities = scores_dict[sector]['activities']\n",
    "        \n",
    "        # Calculate LCA scores using the specified method\n",
    "        lca_scores = compare_activities_multiple_methods(\n",
    "            activities_list=sector_activities,\n",
    "            methods=method_dict,\n",
    "            identifier=sector,\n",
    "            mode='absolute'\n",
    "        )\n",
    "        \n",
    "        # Apply the small_inputs_to_other_column function with the cutoff value\n",
    "        lca_scores_cut = small_inputs_to_other_column(lca_scores, cutoff)\n",
    "        \n",
    "        # Save the LCA scores to the scores_dict\n",
    "        scores_dict[sector]['lca_scores'] = lca_scores_cut\n",
    "\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def _add_statistics(df, column_name='total'):\n",
    "\n",
    "    '''\n",
    "    It is called in the function sector_lca_scores_to_excel_and_column_positions\n",
    "\n",
    "    It adds statistical indicators to a dataframe based on total column which are used for plotting.\n",
    "\n",
    "    returns updated dataframe\n",
    "    '''\n",
    "    \n",
    "    #Need a rank row to plot the total LCA scores in descending order (satter opepyxl function takes in non categorial values)\n",
    "    df['rank'] = df[column_name].rank(method=\"first\", ascending=False)\n",
    "\n",
    "    # Calculate mean, standard deviation, and IQR\n",
    "    df['mean'] = df[column_name].mean()\n",
    "    df['2std_abv'] = df['mean'] + df[column_name].std() * 2\n",
    "    df['2std_blw'] = df['mean'] - df[column_name].std() * 2\n",
    "    df['q1'] = df[column_name].quantile(0.25)\n",
    "    df['q3'] = df[column_name].quantile(0.75)\n",
    "    \n",
    "    # Reorder the columns to place the new columns after 'total'\n",
    "    cols = df.columns.tolist()\n",
    "    total_index = cols.index(column_name) + 1\n",
    "    new_cols = ['rank', 'mean', '2std_abv', '2std_blw', 'q1', 'q3']\n",
    "    cols = cols[:total_index] + new_cols + cols[total_index:-len(new_cols)]\n",
    "    \n",
    "    return df[cols]\n",
    "\n",
    "\n",
    "def _find_first_input_column(df):\n",
    "    '''\n",
    "    It is called in the function sector_lca_scores_to_excel_and_column_positions. Needs to be called before _clean_column_labels function.\n",
    "    Detects the first column in the dataframe which contains input contribution data and saves its index. \n",
    "    This is relevant for calling the right column for defining the to be plotted data dynamically as not all dataframes have the same column order (some contain \"direct emissions\" for instance).\n",
    "    '''\n",
    "    \n",
    "    def _clean_label(label):\n",
    "        return label if label is not None else 'Unnamed'\n",
    "    \n",
    "    # Apply the cleaning function to all column names\n",
    "    df.columns = [_clean_label(col) for col in df.columns]\n",
    "    \n",
    "    # Regular expression pattern to match \"Number: Name\"\n",
    "    pattern = r'^\\d+:\\s*'\n",
    "    \n",
    "    for idx, column in enumerate(df.columns):\n",
    "        if (column is not None and re.match(pattern, column)) or column == 'Unnamed' or column == 'direct emissions':\n",
    "            return idx\n",
    "\n",
    "    return None\n",
    "\n",
    "def _clean_column_labels(df):\n",
    "\n",
    "    '''\n",
    "    It is called in the function sector_lca_scores_to_excel_and_column_positions. Needs to be run after _find_first_input_column.\n",
    "\n",
    "    It removes unnecessary numbers in the column header.\n",
    "\n",
    "    Returns df with formated column labels.\n",
    "    '''\n",
    "    # Function to remove numbers and colon from column names\n",
    "    def _clean_label(label):\n",
    "        if label is None:\n",
    "            return 'Unnamed'  # or return 'Unnamed' if you prefer a placeholder\n",
    "        return re.sub(r'^\\d+:\\s*', '', str(label))\n",
    "\n",
    "    # Apply the cleaning function to all column names\n",
    "    df.columns = [_clean_label(col) for col in df.columns]\n",
    "\n",
    "    return df\n",
    "\n",
    "def _add_sector_marker(df, sector):\n",
    "    '''\n",
    "    It is called in the function sector_lca_scores_to_excel_and_column_positions.\n",
    "\n",
    "    It adds information about the sector for titel and labeling in plotting.\n",
    "\n",
    "    Returns df with added column.\n",
    "    '''\n",
    "    \n",
    "    # Add sector marker column\n",
    "    df['sector']=str(sector) # potentially remove!\n",
    "    # Reorder the columns to move 'sector' after 'product'\n",
    "    columns = list(df.columns)\n",
    "\n",
    "    if 'product' in df.columns:\n",
    "        product_index = columns.index('product')\n",
    "        # Insert 'sector' after 'product'\n",
    "        columns.insert(product_index + 1, columns.pop(columns.index('sector')))\n",
    "    else:\n",
    "        # If 'product' does not exist, 'sector' remains in the last column\n",
    "        columns.append(columns.pop(columns.index('sector')))\n",
    "        \n",
    "    # Reassign the DataFrame with the new column order\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "def _categorize_sheets_by_sector(file_path):\n",
    "    # Load the workbook\n",
    "    workbook = load_workbook(filename=file_path, read_only=True)\n",
    "    \n",
    "    # Initialize a dictionary to hold sectors and their corresponding sheet names\n",
    "    worksheet_dict = {}\n",
    "    \n",
    "    # Iterate over all sheet names in the workbook\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        # Skip combined sector sheets (assuming these sheets don't have an underscore)\n",
    "        if '_' not in sheet_name:\n",
    "            continue\n",
    "        \n",
    "        # Split the sheet name to extract the sector (assumes sector is the first part)\n",
    "        sector = sheet_name.split('_')[0]\n",
    "        \n",
    "        # Add the sheet name to the corresponding sector in the dictionary\n",
    "        if sector in worksheet_dict:\n",
    "            worksheet_dict[sector].append(sheet_name)\n",
    "        else:\n",
    "            worksheet_dict[sector] = [sheet_name]\n",
    "    \n",
    "    return worksheet_dict\n",
    "\n",
    "def _add_database_key(df):\n",
    "    for act in \n",
    "    df['key']="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def sector_lca_scores_to_excel(scores_dict, excel_file_name):\n",
    "    \"\"\" \n",
    "    What it does:\n",
    "        - Creates a dataframe for each method and sector from the lca scores dictionary\n",
    "        - Before storing each df in a worksheet in an excel file it:\n",
    "                - shortens the column labels of the input (removing cpc code)\n",
    "                - adds a sector name marker for keeping track in excel (when plotting can use it for labeling)\n",
    "                - adds statistics for plotting\n",
    "                - creates a dictionary which holds the indexes to the columns we need to call for plotting, this makes it dynamic. Otherwise need to hardcode index column number for openpxyl.\n",
    "    What it returns:\n",
    "        - Returns the index positions dictionary where the key is \"sector_method\"\n",
    "        - Creates excel file as defined by user\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store positions of columns for each method\n",
    "    column_positions = {}\n",
    "\n",
    "    # DataFrames to store combined sector data\n",
    "    combined_sector_dfs = {}\n",
    "    method_dfs = []\n",
    "\n",
    "    # Process each sector and its methods\n",
    "    for sector in scores_dict.keys():\n",
    "        sector_dfs = []\n",
    "        lca_scores = scores_dict[sector]['lca_scores']\n",
    "\n",
    "        # Process each method for the current sector\n",
    "        for method, table in lca_scores.items():\n",
    "            df = pd.DataFrame(table)\n",
    "\n",
    "            # Add sector marker\n",
    "            df = _add_sector_marker(df, sector)\n",
    "\n",
    "            # Add statistics to the DataFrame\n",
    "            df = _add_statistics(df)\n",
    "\n",
    "            # Add database key aka activity key\n",
    "            df = _add_database_key(df)\n",
    "\n",
    "            # Get the index values of columns\n",
    "            columns_of_interest = [\"total\", \"rank\", \"mean\", \"2std_abv\", \"2std_blw\", \"q1\", \"q3\", \"method\", \"method unit\"]\n",
    "            positions = {col: df.columns.get_loc(col) for col in columns_of_interest if col in df.columns}\n",
    "            column_positions[f\"{sector}_{method}\"] = positions\n",
    "\n",
    "            # Find the first input column and add it to the positions dictionary\n",
    "            first_input_col_index = _find_first_input_column(df)\n",
    "            if first_input_col_index is not None:\n",
    "                positions[\"first_input\"] = first_input_col_index\n",
    "\n",
    "            # Store the positions for this method\n",
    "            column_positions[f\"{sector}_{method}\"] = positions\n",
    "\n",
    "            # Remove CPC from input labels\n",
    "            df = _clean_column_labels(df)\n",
    "\n",
    "            sector_dfs.append(df)\n",
    "\n",
    "            # Store method-specific DataFrames for later\n",
    "            method_dfs.append((f\"{method}\", df))\n",
    "\n",
    "        # Combine all dataframes for this sector\n",
    "        combined_df = pd.concat(sector_dfs, axis=0, ignore_index=True, sort=False).fillna(0)\n",
    "        combined_sector_dfs[sector] = combined_df\n",
    "\n",
    "    # Write to Excel file\n",
    "    with pd.ExcelWriter(excel_file_name, engine='openpyxl') as writer:\n",
    "        # First write all combined sector sheets\n",
    "        for sector, combined_df in combined_sector_dfs.items():\n",
    "            worksheet_name_big = f\"{sector}\"\n",
    "            if len(worksheet_name_big) > 31:\n",
    "                worksheet_name_big = worksheet_name_big[:31]\n",
    "            combined_df.to_excel(writer, sheet_name=worksheet_name_big, index=False)\n",
    "\n",
    "        # Then write all method-specific sheets\n",
    "        for worksheet_name, df in method_dfs:\n",
    "            if len(worksheet_name) > 31:\n",
    "                worksheet_name = worksheet_name[:31]\n",
    "            df.to_excel(writer, sheet_name=worksheet_name, index=False)\n",
    "\n",
    "    return column_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pos=sector_lca_scores_to_excel(scores_dictionary_one, '2808_v7.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import ScatterChart, Reference, Series\n",
    "\n",
    "def dot_plots_xcl(filepath_workbook, index_positions):\n",
    "\n",
    "    worksheet_dict = _categorize_sheets_by_sector(filepath_workbook)\n",
    "    \n",
    "    # Load the workbook\n",
    "    wb = load_workbook(filepath_workbook)\n",
    "    \n",
    "    # Iterate over each sector and its associated worksheets\n",
    "    for sector, worksheet_names in worksheet_dict.items():\n",
    "        \n",
    "        # Create or get the chart sheet for the current sector\n",
    "        chart_sheet_name = f\"{sector}_charts\"\n",
    "        if chart_sheet_name in wb.sheetnames:\n",
    "            ws_charts = wb[chart_sheet_name]\n",
    "        else:\n",
    "            ws_charts = wb.create_sheet(chart_sheet_name)        \n",
    "                \n",
    "        # Initial position for the first chart\n",
    "        current_row = 1  # Start placing charts from row 1\n",
    "        current_col = 1  # Start placing charts from column 1\n",
    "        chart_height = 30  # Number of rows a chart occupies\n",
    "        chart_width = 12   # Number of columns a chart occupies\n",
    "        charts_per_row = 3  # Number of charts per row\n",
    "        \n",
    "        # Iterate over each worksheet name in the current sector\n",
    "        for i, worksheet_name in enumerate(worksheet_names):\n",
    "            ws = wb[worksheet_name]\n",
    "\n",
    "            # Find min_row, max_row and max_column\n",
    "            max_row = ws.max_row\n",
    "            max_column = ws.max_column\n",
    "            min_row = 1\n",
    "\n",
    "            # Find the key in index_positions that contains worksheet_name\n",
    "            matching_key = None\n",
    "            for key in index_positions.keys():\n",
    "                if worksheet_name in key:\n",
    "                    matching_key = key\n",
    "                    break\n",
    "\n",
    "            if not matching_key:\n",
    "                print(f\"Warning: No matching key found for worksheet '{worksheet_name}'. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Retrieve the column positions from the index_positions dictionary\n",
    "            positions = index_positions[matching_key]\n",
    "            total_col = positions.get(\"total\", None) + 1\n",
    "            rank_col = positions.get(\"rank\", None) + 1\n",
    "            mean_col = positions.get(\"mean\", None) + 1\n",
    "            std_adv_col = positions.get(\"2std_abv\", None) + 1\n",
    "            std_blw_col = positions.get(\"2std_blw\", None) + 1\n",
    "            q1_col = positions.get(\"q1\", None) + 1\n",
    "            q3_col = positions.get(\"q3\", None) + 1\n",
    "            method_col = positions.get(\"method\", None) + 1\n",
    "            method_unit_col = positions.get(\"method unit\", None) + 1\n",
    "            \n",
    "            # Ensure that all required columns are present\n",
    "            if None in [total_col, rank_col, mean_col, std_adv_col, std_blw_col, q1_col, q3_col, method_col, method_unit_col]:\n",
    "                print(f\"Warning: Missing columns in worksheet '{worksheet_name}' for sector '{sector}'. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Create a ScatterChart (or other chart type as needed)\n",
    "            chart = ScatterChart()\n",
    "\n",
    "            # Chart titles\n",
    "            method_value = ws.cell(row=2, column=method_col).value\n",
    "            chart.title = f\"{method_value} LCA scores for {sector} sector\" \n",
    "            \n",
    "            method_unit_value = ws.cell(row=2, column=method_unit_col).value\n",
    "            chart.y_axis.title = f\"{method_unit_value}\"\n",
    "            chart.x_axis.title = 'activity rank'\n",
    "            # Avoid overlap\n",
    "            chart.title.overlay = False\n",
    "            chart.x_axis.title.overlay = False\n",
    "            chart.y_axis.title.overlay = False \n",
    "\n",
    "            # Define the data range for the chart\n",
    "            y_values = Reference(ws, min_col=total_col, min_row=min_row, max_row=max_row)\n",
    "            x_values = Reference(ws, min_col=rank_col, min_row=min_row, max_row=max_row)\n",
    "\n",
    "            # Create a series and add it to the chart\n",
    "            series = Series(y_values, x_values, title_from_data=True)\n",
    "            chart.series.append(series)\n",
    "            chart.style = 9\n",
    "\n",
    "            # Customize the series to show only markers (dots)\n",
    "            series.marker.symbol = \"circle\"\n",
    "            series.marker.size = 5\n",
    "            series.graphicalProperties.line.noFill = True\n",
    "\n",
    "            # ADJUST X-AXIS\n",
    "            chart.x_axis.tickLblPos = \"low\"\n",
    "            chart.x_axis.majorGridlines = None \n",
    "            chart.x_axis.tickMarkSkip = 1  # Show all tick marks, this adresses the tick lines \n",
    "            chart.x_axis.tickLblSkip = 1  # Show all labels, doesnt work\n",
    "\n",
    "            chart.x_axis.scaling.orientation = \"minMax\"\n",
    "            chart.x_axis.crosses = \"autoZero\"\n",
    "            chart.x_axis.axPos = \"b\"\n",
    "            chart.x_axis.delete = False\n",
    "\n",
    "            # ADJUST Y-AXIS\n",
    "            chart.y_axis.tickLblPos = \"nextTo\"  # Position the labels next to the tick marks\n",
    "            chart.y_axis.delete = False  # Ensure axis is not deleted\n",
    "            chart.y_axis.number_format = '0.00000'\n",
    "            chart.y_axis.majorGridlines = None \n",
    "\n",
    "            # ADD STATS\n",
    "            # MEAN\n",
    "            mean_y = Reference(ws, min_col=mean_col, min_row=min_row, max_row=max_row)\n",
    "            mean_series = Series(mean_y, x_values, title_from_data=\"True\")\n",
    "            chart.series.append(mean_series)\n",
    "            mean_series.marker.symbol = \"none\"  # No markers, just a line\n",
    "            mean_series.graphicalProperties.line.solidFill = \"FF0000\"  # Red line for mean value\n",
    "            mean_series.graphicalProperties.line.width = 10000  # Set line width (default units are EMUs)\n",
    "\n",
    "            # IQR\n",
    "            iqr1 = Reference(ws, min_col=q1_col, min_row=min_row, max_row=max_row)\n",
    "            iqr3 = Reference(ws, min_col=q3_col, min_row=min_row, max_row=max_row)\n",
    "            iqr1_series = Series(iqr1, x_values, title_from_data=\"True\")\n",
    "            iqr3_series = Series(iqr3, x_values, title_from_data=\"True\")\n",
    "            chart.series.append(iqr1_series)\n",
    "            chart.series.append(iqr3_series)\n",
    "            iqr1_series.marker.symbol = \"none\"  # No markers, just a line\n",
    "            iqr3_series.marker.symbol = \"none\"\n",
    "            iqr1_series.graphicalProperties.line.solidFill = \"6082B6\"  # Blue line \n",
    "            iqr3_series.graphicalProperties.line.solidFill = \"6082B6\"  \n",
    "            iqr1_series.graphicalProperties.line.width = 10000  # Set line width (default units are EMUs)\n",
    "            iqr3_series.graphicalProperties.line.width = 10000  # Set line width (default units are EMUs)\n",
    "\n",
    "            # STD\n",
    "            std_abv = Reference(ws, min_col=std_adv_col, min_row=min_row, max_row=max_row)\n",
    "            std_blw = Reference(ws, min_col=std_blw_col, min_row=min_row, max_row=max_row)\n",
    "            std_abv_series = Series(std_abv, x_values, title_from_data=\"True\")\n",
    "            std_blw_series = Series(std_blw, x_values, title_from_data=\"True\")\n",
    "            chart.series.append(std_abv_series)\n",
    "            chart.series.append(std_blw_series)\n",
    "            std_abv_series.marker.symbol = \"none\"  # No markers, just a line\n",
    "            std_blw_series.marker.symbol = \"none\"\n",
    "            std_abv_series.graphicalProperties.line.solidFill = \"FFC300\"  # yellow line\n",
    "            std_blw_series.graphicalProperties.line.solidFill = \"FFC300\"  \n",
    "            std_abv_series.graphicalProperties.line.width = 10000  # Set line width (default units are EMUs)\n",
    "            std_blw_series.graphicalProperties.line.width = 10000  # Set line width (default units are EMUs)\n",
    "\n",
    "            # Set legend position to the right of the plot area\n",
    "            chart.legend.position = 'r'  # 'r' for right\n",
    "            chart.legend.overlay = False\n",
    "\n",
    "            # Adjust chart dimensions\n",
    "            chart.width = 20  # Width of the chart\n",
    "            chart.height = 14  # Height of the chart\n",
    "\n",
    "            # Calculate the position for this chart\n",
    "            position = ws_charts.cell(row=current_row, column=current_col).coordinate\n",
    "            ws_charts.add_chart(chart, position)\n",
    "            \n",
    "            # Update position for the next chart\n",
    "            current_col += chart_width +1 \n",
    "            if (i + 1) % charts_per_row == 0:  # Move to the next row after placing `charts_per_row` charts\n",
    "                current_row += chart_height +1\n",
    "                current_col = 1  # Reset to the first column\n",
    "\n",
    "        # Move the chart sheet to the first position\n",
    "        wb._sheets.remove(ws_charts)\n",
    "        wb._sheets.insert(0, ws_charts)\n",
    "\n",
    "    wb.save(filepath_workbook)\n",
    "    return current_row\n",
    "\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "def stacked_bars_xcl(filepath_workbook, index_positions, current_row_dot_plot):\n",
    "\n",
    "    worksheet_dict = _categorize_sheets_by_sector(filepath_workbook)\n",
    "    # Load the workbook\n",
    "    wb = load_workbook(filepath_workbook)\n",
    "    \n",
    "    # Iterate over each sector and its associated worksheets\n",
    "    for sector, worksheet_names in worksheet_dict.items():\n",
    "        \n",
    "        # Create or get the chart sheet for the current sector\n",
    "        chart_sheet_name = f\"{sector}_charts\"\n",
    "        if chart_sheet_name in wb.sheetnames:\n",
    "            ws_charts = wb[chart_sheet_name]\n",
    "        else:\n",
    "            ws_charts = wb.create_sheet(chart_sheet_name)\n",
    "                \n",
    "        # Initial position for the first chart\n",
    "        chart_height = 30  # Number of rows a chart occupies\n",
    "        chart_width = 12   # Number of columns a chart occupies\n",
    "        current_row = current_row_dot_plot + chart_height # Start placing charts from row where dot plots have left of\n",
    "        current_col = 1  # Start placing charts from column 1\n",
    "        charts_per_row = 3  # Number of charts per row\n",
    "        \n",
    "        # Iterate over each worksheet name in the current sector\n",
    "        for i, worksheet_name in enumerate(worksheet_names):\n",
    "            ws = wb[worksheet_name]\n",
    "\n",
    "            # Find the key in index_positions that contains worksheet_name\n",
    "            matching_key = None\n",
    "            for key in index_positions.keys():\n",
    "                if worksheet_name in key:\n",
    "                    matching_key = key\n",
    "                    break\n",
    "\n",
    "            if not matching_key:\n",
    "                print(f\"Warning: No matching key found for worksheet '{worksheet_name}'. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Retrieve the column positions from the index_positions dictionary\n",
    "            positions = index_positions[matching_key]\n",
    "\n",
    "            # Find min_row, max_row and max_column\n",
    "            max_row = ws.max_row\n",
    "            max_column = ws.max_column\n",
    "            input_min_col = positions.get(\"first_input\", None) + 1\n",
    "            rank_col = positions.get(\"rank\", None) + 1\n",
    "            method_col = positions.get(\"method\", None) + 1\n",
    "            method_unit_col = positions.get(\"method unit\", None) + 1\n",
    "\n",
    "            chart = BarChart()\n",
    "            chart.type = \"bar\"\n",
    "            chart.style = 2\n",
    "            chart.grouping = \"stacked\"\n",
    "            chart.overlap = 100\n",
    "\n",
    "            # Chart titles\n",
    "            method_value = ws.cell(row=2, column=method_col).value\n",
    "            chart.title = f\"{sector} sector inputs contributions to {method_value}\"\n",
    "\n",
    "            method_unit_value = ws.cell(row=2, column=method_unit_col).value\n",
    "            chart.y_axis.title = f\"{method_unit_value}\"\n",
    "            \n",
    "            chart.x_axis.title = 'activity rank'\n",
    "\n",
    "            # Avoid overlap\n",
    "            chart.title.overlay = False\n",
    "            chart.x_axis.title.overlay = False\n",
    "            chart.y_axis.title.overlay = False \n",
    "            chart.legend.overlay = False\n",
    "\n",
    "            # Define data\n",
    "            data = Reference(ws, min_col=input_min_col, min_row=1, max_row=max_row, max_col=max_column)\n",
    "            cats = Reference(ws, min_col=rank_col, min_row=2, max_row=max_row)\n",
    "\n",
    "            chart.add_data(data, titles_from_data=True)\n",
    "            chart.set_categories(cats)\n",
    "            chart.shape = 4\n",
    "\n",
    "            # Modify each series in the chart to disable the inversion of negative values \n",
    "            for series in chart.series:\n",
    "                series.invertIfNegative = False\n",
    "\n",
    "            # y-axis ticks\n",
    "            chart.y_axis.tickLblPos = \"nextTo\"\n",
    "            chart.y_axis.delete = False  # Ensure axis is not deleted\n",
    "            chart.y_axis.number_format = '0.000'\n",
    "\n",
    "            # Adjust chart dimensions\n",
    "            chart.width = 20  # Width of the chart\n",
    "            chart.height = 14  # Height of the chart\n",
    "\n",
    "            # Add the chart to the chart worksheet\n",
    "            # Calculate the position for this chart\n",
    "            position = ws_charts.cell(row=current_row, column=current_col).coordinate\n",
    "            ws_charts.add_chart(chart, position)\n",
    "            \n",
    "            # Update position for the next chart\n",
    "            current_col += chart_width +1\n",
    "            if (i + 1) % charts_per_row == 0:  # Move to the next row after placing `charts_per_row` charts\n",
    "                current_row += chart_height +1\n",
    "                current_col = 1  # Reset to the first column\n",
    "\n",
    "        # Move the chart sheet to the first position\n",
    "        wb._sheets.remove(ws_charts)\n",
    "        wb._sheets.insert(0, ws_charts)\n",
    "        \n",
    "    wb.save(filepath_workbook)\n",
    "    return current_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from dopo import generate_sets_from_filters\n",
    "from dopo import compare_activities_multiple_methods\n",
    "from dopo import small_inputs_to_other_column\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import ScatterChart, Reference, Series\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "def _lca_scores_compare(database_dict, method_dict):\n",
    "    # Dictionary to store DataFrames for each sector\n",
    "    sector_dataframes = {}\n",
    "\n",
    "    # Labels for the DataFrame columns\n",
    "    labels = [\n",
    "        \"activity\",\n",
    "        \"activity key\",\n",
    "        \"reference product\",\n",
    "        \"location\",\n",
    "        \"method\",\n",
    "        \"method unit\",\n",
    "        \"total\",\n",
    "    ]\n",
    "\n",
    "    # Loop through each sector in the database_dict\n",
    "    for sector, sector_data in database_dict.items():\n",
    "        # Initialize a dictionary to hold DataFrames for each method in the current sector\n",
    "        method_dataframes = {}\n",
    "\n",
    "        # Loop through each method in method_dict\n",
    "        for meth_key, meth_info in method_dict.items():\n",
    "            data = []  # Initialize a new list to hold data for the current method\n",
    "            \n",
    "            # Extract the 'method name' tuple from the current method info\n",
    "            method_name = meth_info['method name']\n",
    "            method_short_name=meth_info['short name']\n",
    "            method_unit = meth_info['unit']\n",
    "\n",
    "            # Now loop through each activity in the sector\n",
    "            for act in sector_data['activities']:\n",
    "                # Ensure the activity is an instance of the expected class\n",
    "                if not isinstance(act, bd.backends.peewee.proxies.Activity):\n",
    "                    raise ValueError(\"`activities` must be an iterable of `Activity` instances\")\n",
    "                \n",
    "                # Perform LCA calculations\n",
    "                lca = bw.LCA({act: 1}, method_name)\n",
    "                lca.lci()\n",
    "                lca.lcia()\n",
    "                \n",
    "                # Collect data for the current activity and method\n",
    "                data.append([\n",
    "                    act[\"name\"],\n",
    "                    act.key,\n",
    "                    act.get(\"reference product\"),\n",
    "                    act.get(\"location\", \"\")[:25],\n",
    "                    method_short_name,\n",
    "                    method_unit,\n",
    "                    lca.score,\n",
    "                ])\n",
    "            \n",
    "            # Convert the data list to a DataFrame and store it in the sector's dictionary\n",
    "            method_dataframes[method_short_name] = pd.DataFrame(data, columns=labels)\n",
    "\n",
    "        # Store the method_dataframes dictionary in the sector_dataframes dictionary\n",
    "        sector_dataframes[sector] = method_dataframes\n",
    "\n",
    "    # Now `sector_dataframes` is a dictionary where each key is a sector, and the value is another dictionary with method names and their corresponding DataFrames\n",
    "    return sector_dataframes\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def _relative_changes_df(database_dict_eco, database_dict_premise, method_dict):\n",
    "\n",
    "    ecoinvent_scores = _lca_scores_compare(database_dict_eco, method_dict)\n",
    "    premise_scores = _lca_scores_compare(database_dict_premise, method_dict)\n",
    "\n",
    "    relative_dict = {}\n",
    "\n",
    "    # Iterate over sectors\n",
    "    for sector_key in ecoinvent_scores:\n",
    "        # Initialize the sector key in the output dictionary\n",
    "        if sector_key not in relative_dict:\n",
    "            relative_dict[sector_key] = {}\n",
    "\n",
    "        # Iterate over methods within the sector\n",
    "        for method_key in ecoinvent_scores[sector_key]:\n",
    "            # Check if the method_key exists in both dictionaries to avoid KeyError\n",
    "            if method_key in premise_scores.get(sector_key, {}):\n",
    "                # Get the corresponding DataFrames\n",
    "                df_ei = ecoinvent_scores[sector_key][method_key]\n",
    "                df_premise = premise_scores[sector_key][method_key]\n",
    "\n",
    "                #print(df_ei['activity key'])\n",
    "                #print(df_premise)\n",
    "\n",
    "                # Split the 'activity key' to extract the second part\n",
    "                df_ei['activity_code'] = df_ei['activity key'].apply(lambda x: x[1])  # Access the second element of the tuple\n",
    "                df_premise['activity_code'] = df_premise['activity key'].apply(lambda x: x[1])\n",
    "\n",
    "                # Merge the two dataframes based on the activity code and method name\n",
    "                merged_df = pd.merge(df_ei, df_premise, on=['activity_code', 'method name'], suffixes=('_ei', '_premise'))\n",
    "\n",
    "                # Calculate the relative change\n",
    "                merged_df['relative_change'] = ((merged_df['total_premise'] - merged_df['total_ei']) / merged_df['total_ei']) * 100\n",
    "\n",
    "                # Store the result in the dictionary\n",
    "                relative_dict[sector_key][method_key] = merged_df\n",
    "\n",
    "    return relative_dict\n",
    "\n",
    "def _add_sector_marker(df, sector):\n",
    "    '''\n",
    "    It is called in the function sector_lca_scores_to_excel_and_column_positions.\n",
    "\n",
    "    It adds information about the sector for titel and labeling in plotting.\n",
    "\n",
    "    Returns df with added column.\n",
    "    '''\n",
    "    \n",
    "    # Add sector marker column\n",
    "    df['sector']=str(sector) # potentially remove!\n",
    "    # Reorder the columns to move 'sector' after 'product'\n",
    "    columns = list(df.columns)\n",
    "\n",
    "    if 'product' in df.columns:\n",
    "        product_index = columns.index('product')\n",
    "        # Insert 'sector' after 'product'\n",
    "        columns.insert(product_index + 1, columns.pop(columns.index('sector')))\n",
    "    else:\n",
    "        # If 'product' does not exist, 'sector' remains in the last column\n",
    "        columns.append(columns.pop(columns.index('sector')))\n",
    "        \n",
    "    # Reassign the DataFrame with the new column order\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "# def relative_changes_db(database_dict_eco, database_dict_premise, method_dict, excel_file):\n",
    "\n",
    "#     relative_dict = (_relative_changes_df(database_dict_eco, database_dict_premise, method_dict))\n",
    "    \n",
    "#     # Prepare to save each LCA score table to a different worksheet in the same Excel file\n",
    "\n",
    "#     column_positions = {} #stores the indexes of columns for plotting\n",
    "#     with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "#         for sector in relative_dict.keys():\n",
    "#             relative_changes = relative_dict[sector]\n",
    "            \n",
    "#             for method, table in relative_changes.items():\n",
    "#                 # Create a DataFrame for the current LCA score table\n",
    "#                 df = pd.DataFrame(table)\n",
    "\n",
    "#                 # Add sector marker\n",
    "#                 df = _add_sector_marker(df, sector) #!! ADJUST      \n",
    "\n",
    "#                 # Sort the DataFrame by 'relative_change' from largest negative to largest positive\n",
    "#                 df = df.sort_values(by='relative_change', ascending=False)\n",
    "\n",
    "#                 # Add a 'rank' column based on the 'relative_change', ranking from most negative to least negative\n",
    "#                 df['rank'] = df['relative_change'].rank(ascending=False, method='dense').astype(int)\n",
    "    \n",
    "#                 # Get the index values of columns\n",
    "#                 columns_of_interest = [\"rank\", \"relative_change\", \"method\", \"method unit\", ]\n",
    "#                 positions = {col: df.columns.get_loc(col) for col in columns_of_interest if col in df.columns}\n",
    "#                 column_positions[method] = positions\n",
    "\n",
    "#                 # Generate worksheet name\n",
    "#                 worksheet_name = f\"{sector}_comparison_{method}\"\n",
    "#                 if len(worksheet_name) > 31:\n",
    "#                     worksheet_name = worksheet_name[:31]\n",
    "\n",
    "#                 # Save the DataFrame to the Excel file in a new worksheet\n",
    "#                 df.to_excel(writer, sheet_name=worksheet_name, index=False)\n",
    "#     return column_positions\n",
    "\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def relative_changes_db(database_dict_eco, database_dict_premise, method_dict, excel_file):\n",
    "    relative_dict = _relative_changes_df(database_dict_eco, database_dict_premise, method_dict)\n",
    "    \n",
    "    # Load existing workbook and get existing sheet names\n",
    "    try:\n",
    "        book = load_workbook(excel_file)\n",
    "        existing_sheets = book.sheetnames\n",
    "    except FileNotFoundError:\n",
    "        # If the file does not exist, we will create a new one, so no need to check existing sheets\n",
    "        existing_sheets = []\n",
    "    \n",
    "    column_positions = {}  # stores the indexes of columns for plotting\n",
    "    \n",
    "    with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a') as writer:\n",
    "        for sector in relative_dict.keys():\n",
    "            relative_changes = relative_dict[sector]\n",
    "            \n",
    "            for method, table in relative_changes.items():\n",
    "                # Create a DataFrame for the current LCA score table\n",
    "                df = pd.DataFrame(table)\n",
    "\n",
    "                # Add sector marker\n",
    "                df = _add_sector_marker(df, sector) #!! ADJUST      \n",
    "\n",
    "                # Sort the DataFrame by 'relative_change' from largest negative to largest positive\n",
    "                df = df.sort_values(by='relative_change', ascending=False)\n",
    "\n",
    "                # Add a 'rank' column based on the 'relative_change', ranking from most negative to least negative\n",
    "                df['rank'] = df['relative_change'].rank(ascending=False, method='dense').astype(int)\n",
    "    \n",
    "                # Get the index values of columns\n",
    "                columns_of_interest = [\"rank\", \"relative_change\", \"method\", \"method unit\"]\n",
    "                positions = {col: df.columns.get_loc(col) for col in columns_of_interest if col in df.columns}\n",
    "                column_positions[method] = positions\n",
    "\n",
    "                # Generate worksheet name\n",
    "                worksheet_name = f\"{sector}_comparison_{method}\"\n",
    "                if len(worksheet_name) > 31:\n",
    "                    worksheet_name = worksheet_name[:31]\n",
    "                \n",
    "                # Ensure unique sheet name\n",
    "                original_worksheet_name = worksheet_name\n",
    "                counter = 1\n",
    "                while worksheet_name in existing_sheets:\n",
    "                    worksheet_name = f\"{original_worksheet_name}_{counter}\"\n",
    "                    if len(worksheet_name) > 31:\n",
    "                        worksheet_name = worksheet_name[:31]\n",
    "                    counter += 1\n",
    "\n",
    "                # Save the DataFrame to the Excel file in a new worksheet\n",
    "                df.to_excel(writer, sheet_name=worksheet_name, index=False)\n",
    "    \n",
    "    return column_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No matching key found for worksheet 'Steel_charts'. Skipping...\n",
      "Warning: No matching key found for worksheet 'Cement_charts'. Skipping...\n"
     ]
    }
   ],
   "source": [
    "index_post=sector_lca_scores_to_excel(scores_dictionary_one, '2808_v16.xlsx')\n",
    "last_row= dot_plots_xcl('2808_v16.xlsx',index_pos)\n",
    "current_row_stacked_bar=stacked_bars_xcl('2808_v16.xlsx', index_pos, last_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "def stacked_bars_xcl(filepath_workbook, column_positions, current_row_dot_plot):\n",
    "    # Load the workbook\n",
    "    wb = load_workbook(filepath_workbook)\n",
    "    \n",
    "    # Iterate over each sheet in the workbook\n",
    "    for sector in wb.sheetnames:\n",
    "        # Skip chart sheets\n",
    "        if sector.endswith(\"_charts\"):\n",
    "            continue\n",
    "\n",
    "        ws = wb[sector]\n",
    "\n",
    "        # Check if the sector exists in column_positions\n",
    "        if sector not in column_positions:\n",
    "            print(f\"Warning: '{sector}' not found in column_positions. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Create or get the chart sheet for the current sector\n",
    "        chart_sheet_name = f\"{sector}_charts\"\n",
    "        if chart_sheet_name in wb.sheetnames:\n",
    "            ws_charts = wb[chart_sheet_name]\n",
    "        else:\n",
    "            ws_charts = wb.create_sheet(chart_sheet_name)\n",
    "        \n",
    "        # Initial position for the first chart\n",
    "        chart_height = 30  # Number of rows a chart occupies\n",
    "        chart_width = 12   # Number of columns a chart occupies\n",
    "        current_row = current_row_dot_plot + chart_height  # Start placing charts from row where dot plots have left of\n",
    "        current_col = 1  # Start placing charts from column 1\n",
    "        charts_per_row = 3  # Number of charts per row\n",
    "        \n",
    "        # Retrieve the first metric to get the method column index\n",
    "        first_metric_positions = next(iter(column_positions[sector].values()))\n",
    "        method_col_idx = first_metric_positions[\"method\"] + 1\n",
    "        \n",
    "        # Get the unique methods present in the data\n",
    "        methods = list(set([ws.cell(row=i, column=method_col_idx).value for i in range(2, ws.max_row + 1)]))\n",
    "        \n",
    "        # Iterate over each unique method and create a chart\n",
    "        for method in methods:\n",
    "            # Filter rows based on the current method\n",
    "            filtered_rows = [i for i in range(2, ws.max_row + 1) if ws.cell(row=i, column=method_col_idx).value == method]\n",
    "\n",
    "            if not filtered_rows:\n",
    "                continue\n",
    "\n",
    "            # Retrieve the column positions from the index_positions dictionary\n",
    "            positions = column_positions[sector].get(method, {})\n",
    "\n",
    "            # Find min_row, max_row and max_column\n",
    "            max_row = ws.max_row\n",
    "            # input_min_col = positions.get(\"first_input\", None) + 1\n",
    "            # rank_col = positions.get(\"rank\", None) + 1\n",
    "            # method_col = positions.get(\"method\", None) + 1\n",
    "            # method_unit_col = positions.get(\"method unit\", None) + 1\n",
    "\n",
    "            chart = BarChart()\n",
    "            chart.type = \"bar\"\n",
    "            chart.style = 2\n",
    "            chart.grouping = \"stacked\"\n",
    "            chart.overlap = 100\n",
    "\n",
    "            # Chart titles\n",
    "            chart.title = f\"{sector} sector inputs contributions to {method}\"\n",
    "\n",
    "            method_unit_value = ws.cell(row=2, column=first_metric_positions[\"method unit\"] + 1).value\n",
    "            chart.y_axis.title = f\"{method_unit_value}\"\n",
    "            chart.x_axis.title = 'activity rank'\n",
    "\n",
    "            # Avoid overlap\n",
    "            chart.title.overlay = False\n",
    "            chart.x_axis.title.overlay = False\n",
    "            chart.y_axis.title.overlay = False \n",
    "            chart.legend.overlay = False\n",
    "\n",
    "            # Define data\n",
    "            data = Reference(ws, min_col=first_metric_positions['total']+2, max_col= ws.max_column, min_row=filtered_rows[0], max_row=filtered_rows[-1]) #max_col=input_min_col + len(filtered_rows) - 1)\n",
    "            cats = Reference(ws, min_col=first_metric_positions[\"rank\"] + 1, min_row=filtered_rows[0], max_row=filtered_rows[-1])\n",
    "\n",
    "            chart.add_data(data, titles_from_data=True)\n",
    "            chart.set_categories(cats)\n",
    "            chart.shape = 4\n",
    "\n",
    "            # Modify each series in the chart to disable the inversion of negative values \n",
    "            for series in chart.series:\n",
    "                series.invertIfNegative = False\n",
    "\n",
    "            # y-axis ticks\n",
    "            chart.y_axis.tickLblPos = \"nextTo\"\n",
    "            chart.y_axis.delete = False  # Ensure axis is not deleted\n",
    "            chart.y_axis.number_format = '0.000'\n",
    "\n",
    "            # Adjust chart dimensions\n",
    "            chart.width = 20  # Width of the chart\n",
    "            chart.height = 14  # Height of the chart\n",
    "\n",
    "            # Add the chart to the chart worksheet\n",
    "            # Calculate the position for this chart\n",
    "            position = ws_charts.cell(row=current_row, column=current_col).coordinate\n",
    "            ws_charts.add_chart(chart, position)\n",
    "            \n",
    "            # Update position for the next chart\n",
    "            current_col += chart_width + 1\n",
    "            if len(methods) % charts_per_row == 0:  # Move to the next row after placing `charts_per_row` charts\n",
    "                current_row += chart_height + 1\n",
    "                current_col = 1  # Reset to the first column\n",
    "\n",
    "        # Move the chart sheet to the first position\n",
    "        wb._sheets.remove(ws_charts)\n",
    "        wb._sheets.insert(0, ws_charts)\n",
    "    \n",
    "    # Save the workbook\n",
    "    wb.save(filepath_workbook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _categorize_sheets_by_sector_comparison(file_path):\n",
    "    # Load the workbook\n",
    "    workbook = load_workbook(filename=file_path, read_only=True)\n",
    "    \n",
    "    # Initialize a dictionary to hold sectors and their corresponding sheet names\n",
    "    worksheet_dict = {}\n",
    "    \n",
    "    # Iterate over all sheet names in the workbook\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        # Skip combined sector sheets (assuming these sheets don't have an underscore)\n",
    "        if '_comparison' not in sheet_name:\n",
    "            continue\n",
    "        \n",
    "        # Split the sheet name to extract the sector (assumes sector is the first part)\n",
    "        sector = sheet_name.split('_')[0]\n",
    "        \n",
    "        # Add the sheet name to the corresponding sector in the dictionary\n",
    "        if sector in worksheet_dict:\n",
    "            worksheet_dict[sector].append(sheet_name)\n",
    "        else:\n",
    "            worksheet_dict[sector] = [sheet_name]\n",
    "    \n",
    "    return worksheet_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "def barchart_compare_db_xcl(filename, current_row_stacked_bar): #, index_positions=None):\n",
    "      \n",
    "    worksheet_dict=_categorize_sheets_by_sector_comparison(file_path=filename)\n",
    "    # Load the workbook and select the sheet\n",
    "    wb = load_workbook(filename)\n",
    "\n",
    "    # Iterate over each sector and its associated worksheets\n",
    "    for sector, worksheet_names in worksheet_dict.items():\n",
    "        \n",
    "        # Create or get the chart sheet for the current sector\n",
    "        chart_sheet_name = f\"{sector}_charts\"\n",
    "        if chart_sheet_name in wb.sheetnames:\n",
    "            ws_charts = wb[chart_sheet_name]\n",
    "        else:\n",
    "            ws_charts = wb.create_sheet(chart_sheet_name)  \n",
    "        \n",
    "        # Initial position for the first chart\n",
    "        current_col = 1  # Start placing charts from column 1\n",
    "        chart_height = 30  # Number of rows a chart occupies\n",
    "        chart_width = 12   # Number of columns a chart occupies\n",
    "        charts_per_row = 3  # Number of charts per row\n",
    "        current_row = current_row_stacked_bar + chart_height\n",
    "    \n",
    "        # Iterate over each worksheet name in the current sector\n",
    "        for i, worksheet_name in enumerate(worksheet_names):\n",
    "            ws = wb[worksheet_name]\n",
    "\n",
    "            # # Find the key in index_positions that contains worksheet_name\n",
    "            # matching_key = None\n",
    "            # for key in index_positions.keys():\n",
    "            #     if worksheet_name in key:\n",
    "            #         matching_key = key\n",
    "            #         break\n",
    "\n",
    "            # if not matching_key:\n",
    "            #     print(f\"Warning: No matching key found for worksheet '{worksheet_name}'. Skipping...\")\n",
    "            #     continue\n",
    "\n",
    "            # Retrieve the column positions from the index_positions dictionary\n",
    "            # positions = index_positions[matching_key]\n",
    "\n",
    "            # Find min_row, max_row and max_column\n",
    "            min_col_data = 15 #positions.get(\"relative_change\", None) + 1\n",
    "            rank_col = 17#positions.get(\"rank\", None) + 1\n",
    "            method_col = 5#positions.get(\"method\", None) + 1\n",
    "            method_unit_col = 6#positions.get(\"method unit\", None) + 1\n",
    "\n",
    "            # Create a bar chart\n",
    "            chart = BarChart()\n",
    "            chart.type=\"bar\"\n",
    "            chart.style=2\n",
    "            chart.overlap= 100\n",
    "            chart.title = \"Relative Change in LCA Scores\"\n",
    "\n",
    "            chart.y_axis.title = \"Activity\"\n",
    "            chart.x_axis.title = \"Relative Change (%)\"\n",
    "\n",
    "            # Set the data for the chart\n",
    "            data = Reference(ws, min_col=min_col_data, min_row=1, max_row=ws.max_row)\n",
    "            categories = Reference(ws, min_col=rank_col, min_row=2, max_row=ws.max_row)\n",
    "            chart.add_data(data, titles_from_data=True)\n",
    "            chart.set_categories(categories)\n",
    "\n",
    "            # Modify each series in the chart to disable the inversion of negative values \n",
    "            for series in chart.series:\n",
    "                series.invertIfNegative = False\n",
    "\n",
    "            # y-axis (categories) settings\n",
    "            chart.y_axis.tickLblPos = \"low\"\n",
    "            chart.y_axis.majorGridlines = None \n",
    "            chart.y_axis.tickMarkSkip = 1\n",
    "            chart.y_axis.tickLblSkip = 1\n",
    "            chart.y_axis.delete = False\n",
    "\n",
    "            # x-axis (values) settings\n",
    "            #chart.x_axis.majorGridlines = MajorGridlines()  # Show gridlines for easier reading\n",
    "\n",
    "            # Chart titles\n",
    "            method_value = ws.cell(row=2, column=method_col).value\n",
    "            chart.title = f\"{sector} {method_value} database lca scores relative changes\"\n",
    "\n",
    "            method_unit_value = ws.cell(row=2, column=method_unit_col).value\n",
    "            chart.x_axis.title = f\"Relative Change (%) - {method_unit_value}\"\n",
    "\n",
    "            # Avoid overlap\n",
    "            chart.title.overlay = False\n",
    "            chart.x_axis.title.overlay = False\n",
    "            chart.y_axis.title.overlay = False \n",
    "            chart.legend.overlay = False\n",
    "\n",
    "            # Adjust chart dimensions\n",
    "            chart.width = 20\n",
    "            chart.height = 14\n",
    "            # Calculate the position for this chart\n",
    "            position = ws_charts.cell(row=current_row, column=current_col).coordinate\n",
    "            ws_charts.add_chart(chart, position)\n",
    "\n",
    "            # Update position for the next chart\n",
    "            current_col += chart_width +1 \n",
    "            if (i + 1) % charts_per_row == 0:  # Move to the next row after placing `charts_per_row` charts\n",
    "                current_row += chart_height +1\n",
    "                current_col = 1  # Reset to the first column\n",
    "\n",
    "        # Move the chart sheet to the first position\n",
    "        wb._sheets.remove(ws_charts)\n",
    "        wb._sheets.insert(0, ws_charts)\n",
    "\n",
    "            # Add the chart to a new worksheet\n",
    "            # new_sheet = wb.create_sheet(title=\"LCA Chart\")\n",
    "            # new_sheet.add_chart(chart, \"A1\")\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(filename)\n",
    "\n",
    "    print(f\"Results and chart saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_changes_db(premise_dict, ecoinvent_dict, method_dict, '2808_v16.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results and chart saved to 2808_v15.xlsx\n"
     ]
    }
   ],
   "source": [
    "barchart_compare_db_xcl('2808_v16.xlsx', current_row_stacked_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement': {'yaml': 'yamls\\\\cement_small.yaml',\n",
       "  'yaml identifier': 'Cement',\n",
       "  'activities': ['cement production, Portland' (kilogram, ZA, None),\n",
       "   'cement production, Portland' (kilogram, BR, None),\n",
       "   'cement production, Portland' (kilogram, IN, None),\n",
       "   'cement production, Portland' (kilogram, CA-QC, None),\n",
       "   'cement production, Portland' (kilogram, US, None),\n",
       "   'cement production, Portland' (kilogram, CH, None),\n",
       "   'cement production, Portland' (kilogram, PE, None)]},\n",
       " 'Steel': {'yaml': 'yamls\\\\steel_small.yaml',\n",
       "  'yaml identifier': 'Steel',\n",
       "  'activities': ['steel production, electric, low-alloyed' (kilogram, CH, None),\n",
       "   'steel production, electric, low-alloyed' (kilogram, CA-QC, None),\n",
       "   'steel production, electric, low-alloyed' (kilogram, IN, None),\n",
       "   'steel production, electric, low-alloyed' (kilogram, AT, None)]}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement_global_warming_potential_(gwp100)': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Cement_cumulative_energy_demand_-_non-renewable_energy_resources': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Cement_land_occupation': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Cement_use_of_net_fresh_water': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Steel_global_warming_potential_(gwp100)': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Steel_cumulative_energy_demand_-_non-renewable_energy_resources': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Steel_land_occupation': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Steel_use_of_net_fresh_water': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dopo.lca_to_xcl\n",
    "\n",
    "\n",
    "dopo.sector_lca_scores_to_excel_and_column_positions(scores_dictionary_one, '2808_v5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'sheets' of 'OpenpyxlWriter' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sector_lca_scores_to_big_table(scores_dictionary_one, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2808_v5.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 13\u001b[0m, in \u001b[0;36msector_lca_scores_to_big_table\u001b[1;34m(scores_dict, excel_file_name)\u001b[0m\n\u001b[0;32m     11\u001b[0m book \u001b[38;5;241m=\u001b[39m load_workbook(excel_file)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(excel_file, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m---> 13\u001b[0m     writer\u001b[38;5;241m.\u001b[39msheets \u001b[38;5;241m=\u001b[39m {ws\u001b[38;5;241m.\u001b[39mtitle: ws \u001b[38;5;28;01mfor\u001b[39;00m ws \u001b[38;5;129;01min\u001b[39;00m book\u001b[38;5;241m.\u001b[39mworksheets}  \u001b[38;5;66;03m# Map the existing sheets to the writer\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sector \u001b[38;5;129;01min\u001b[39;00m scores_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     15\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scores_dict[sector])\n",
      "\u001b[1;31mAttributeError\u001b[0m: property 'sheets' of 'OpenpyxlWriter' object has no setter"
     ]
    }
   ],
   "source": [
    "sector_lca_scores_to_big_table(scores_dictionary_one, '2808_v5.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "premise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
