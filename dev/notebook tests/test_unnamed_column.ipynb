{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2 as bw\n",
    "import bw2data as bd\n",
    "import bw2analyzer as ba\n",
    "\n",
    "#reduce?\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dopo\n",
    "from dopo import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biosphere database already present!!! No setup is needed\n"
     ]
    }
   ],
   "source": [
    "bd.projects.set_current(\"premise-validation-try1\")\n",
    "bw.bw2setup()\n",
    "\n",
    "bio3=bw.Database('biosphere3')\n",
    "ei39=bw.Database('ecoinvent 3.9.1 cutoff')\n",
    "ei39SSP2=bw.Database('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sector filters file names/paths\n",
    "\n",
    "cement = 'cement_small.yaml'\n",
    "electricity = 'electricity_small.yaml'\n",
    "fuels= 'fuels_small.yaml'\n",
    "steel = 'steel_small.yaml'\n",
    "transport = 'transport_small.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement': {'yaml': 'yamls\\\\cement_small.yaml', 'yaml identifier': 'Cement'},\n",
       " 'Steel': {'yaml': 'yamls\\\\steel_small.yaml', 'yaml identifier': 'Steel'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_dict={}\n",
    "files_dict['Cement']={'yaml': 'yamls\\cement_small.yaml', \n",
    "                      'yaml identifier': 'Cement'}\n",
    "files_dict['Steel']= {'yaml':'yamls\\steel_small.yaml',\n",
    "                            'yaml identifier': 'Steel'} #yaml identifier is the name of the filter in the yaml file, in the first line.\n",
    "files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cement with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Cement:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '36a53c174f34e672bc15b7e55563685e')\n",
      "Processing Steel with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Steel:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'af6bd1221fc0206541fbaf481397bf0d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '18b0dcf01dd401e1549b3796e3786213')\n",
      "Processing Cement with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Cement:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '36a53c174f34e672bc15b7e55563685e')\n",
      "Processing Steel with database ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27\n",
      "Activities for Steel:\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '18b0dcf01dd401e1549b3796e3786213')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "  ('ei_cutoff_3.9_image_SSP2-RCP19_2050 2024-06-27', 'af6bd1221fc0206541fbaf481397bf0d')\n",
      "Processing Cement with database ecoinvent 3.9.1 cutoff\n",
      "Activities for Cement:\n",
      "  ('ecoinvent 3.9.1 cutoff', 'f8b84f45f50d3bd7ff4feaabdb493f6a')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'a3c2064d83411f7963af550c04c869a1')\n",
      "  ('ecoinvent 3.9.1 cutoff', '36a53c174f34e672bc15b7e55563685e')\n",
      "  ('ecoinvent 3.9.1 cutoff', '3c16b45db40210cd97de6574b2f47aaf')\n",
      "  ('ecoinvent 3.9.1 cutoff', '86841f8c7ee2668f244d3b8e34f41932')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'df49e8f525497f2fbd56bcdc80ff0cde')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'fcb666edf2a01467e555eeff5b4a5bbb')\n",
      "Processing Steel with database ecoinvent 3.9.1 cutoff\n",
      "Activities for Steel:\n",
      "  ('ecoinvent 3.9.1 cutoff', '1dffacc9e0ca08fb55c6b780d7e677dc')\n",
      "  ('ecoinvent 3.9.1 cutoff', 'af6bd1221fc0206541fbaf481397bf0d')\n",
      "  ('ecoinvent 3.9.1 cutoff', '2baa0deb3adc89dfe8cb89d5e078ba8d')\n",
      "  ('ecoinvent 3.9.1 cutoff', '18b0dcf01dd401e1549b3796e3786213')\n"
     ]
    }
   ],
   "source": [
    "import dopo.filter_sectors\n",
    "\n",
    "#for plot 1 and 2\n",
    "dictionary_one = dopo.filter_sectors.process_yaml_files(files_dict, ei39SSP2)\n",
    "\n",
    "#for comparison\n",
    "premise_dict = dopo.filter_sectors.process_yaml_files(files_dict, ei39SSP2)\n",
    "ecoinvent_dict = dopo.filter_sectors.process_yaml_files(files_dict, ei39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method_1': {'object': Brightway2 Method: IPCC 2013: climate change: global warming potential (GWP100),\n",
       "  'method name': ('IPCC 2013',\n",
       "   'climate change',\n",
       "   'global warming potential (GWP100)'),\n",
       "  'short name': 'global warming potential (GWP100)',\n",
       "  'unit': 'kg CO2-Eq'},\n",
       " 'method_2': {'object': Brightway2 Method: EN15804: inventory indicators ISO21930: Cumulative Energy Demand - non-renewable energy resources,\n",
       "  'method name': ('EN15804',\n",
       "   'inventory indicators ISO21930',\n",
       "   'Cumulative Energy Demand - non-renewable energy resources'),\n",
       "  'short name': 'Cumulative Energy Demand - non-renewable energy resources',\n",
       "  'unit': 'megajoule'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder=dopo.methods.MethodFinder()\n",
    "\n",
    "finder.find_and_create_method(criteria=['IPCC', '2013', 'GWP100'], exclude=['no LT'])\n",
    "finder.find_and_create_method(criteria=['EN15804','Cumulative', 'non-renewable' ])\n",
    "#finder.find_and_create_method(criteria=['land occupation','selected'])\n",
    "#finder.find_and_create_method(criteria=['EN15804','fresh water'])\n",
    "method_dict=finder.get_all_methods()\n",
    "method_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCA Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "from os.path import commonprefix\n",
    "\n",
    "import bw2calc as bc\n",
    "import bw2data as bd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def aggregated_dict(activity):\n",
    "    \"\"\"Return dictionary of inputs aggregated by input reference product.\"\"\"\n",
    "    results = {}\n",
    "    for exc in activity.technosphere():\n",
    "        results[exc.input[\"reference product\"]] = (\n",
    "            results.setdefault(exc.input[\"reference product\"], 0) + exc[\"amount\"]\n",
    "        )\n",
    "\n",
    "    for exc in activity.biosphere():\n",
    "        results[exc.input[\"name\"]] = (\n",
    "            results.setdefault(exc.input[\"name\"], 0) + exc[\"amount\"]\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def compare_dictionaries(one, two, rel_tol=1e-4, abs_tol=1e-9):\n",
    "    \"\"\"Compare two dictionaries with form ``{str: float}``, and return a set of keys where differences where present.\n",
    "\n",
    "    Tolerance values are inputs to `math.isclose <https://docs.python.org/3/library/math.html#math.isclose>`__.\"\"\"\n",
    "    return (\n",
    "        set(one)\n",
    "        .symmetric_difference(set(two))\n",
    "        .union(\n",
    "            {\n",
    "                key\n",
    "                for key in one\n",
    "                if key in two\n",
    "                and not math.isclose(\n",
    "                    a=one[key], b=two[key], rel_tol=rel_tol, abs_tol=abs_tol\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_differences_in_inputs(\n",
    "    activity, rel_tol=1e-4, abs_tol=1e-9, locations=None, as_dataframe=False\n",
    "):\n",
    "    \"\"\"Given an ``Activity``, try to see if other activities in the same database (with the same name and\n",
    "    reference product) have the same input levels.\n",
    "\n",
    "    Tolerance values are inputs to `math.isclose <https://docs.python.org/3/library/math.html#math.isclose>`__.\n",
    "\n",
    "    If differences are present, a difference dictionary is constructed, with the form:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        {Activity instance: [(name of input flow (str), amount)]}\n",
    "\n",
    "    Note that this doesn't reference a specific exchange, but rather sums **all exchanges with the same input reference product**.\n",
    "\n",
    "    Assumes that all similar activities produce the same amount of reference product.\n",
    "\n",
    "    ``(x, y)``, where ``x`` is the number of similar activities, and ``y`` is a dictionary of the differences. This dictionary is empty if no differences are found.\n",
    "\n",
    "    Args:\n",
    "        activity: ``Activity``. Activity to analyze.\n",
    "        rel_tol: float. Relative tolerance to decide if two inputs are the same. See above.\n",
    "        abs_tol: float. Absolute tolerance to decide if two inputs are the same. See above.\n",
    "        locations: list, optional. Locations to restrict comparison to, if present.\n",
    "        as_dataframe: bool. Return results as pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        dict or ``pandas.DataFrame``.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    assert isinstance(activity, bd.backends.proxies.Activity)\n",
    "\n",
    "    try:\n",
    "        similar = [\n",
    "            obj\n",
    "            for obj in bd.Database(activity[\"database\"])\n",
    "            if obj != activity\n",
    "            and obj.get(\"reference product\") == activity.get(\"reference product\")\n",
    "            and obj.get(\"name\") == activity[\"name\"]\n",
    "            and (not locations or obj.get(\"location\") in locations)\n",
    "        ]\n",
    "    except KeyError:\n",
    "        raise ValueError(\"Given activity has no `name`; can't find similar names\")\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    origin_dict = aggregated_dict(activity)\n",
    "\n",
    "    for target in similar:\n",
    "        target_dict = aggregated_dict(target)\n",
    "        difference = compare_dictionaries(origin_dict, target_dict, rel_tol, abs_tol)\n",
    "        if difference:\n",
    "            if activity not in result:\n",
    "                result[activity] = {}\n",
    "            result[activity].update(\n",
    "                {key: value for key, value in origin_dict.items() if key in difference}\n",
    "            )\n",
    "            result[target] = {\n",
    "                key: value for key, value in target_dict.items() if key in difference\n",
    "            }\n",
    "\n",
    "    if as_dataframe:\n",
    "        df = DataFrame(\n",
    "            [{\"location\": obj.get(\"location\"), **result[obj]} for obj in result]\n",
    "        )\n",
    "        df.set_index(\"location\", inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_activities_by_lcia_score(activities, lcia_method, band=0.1):\n",
    "    \"\"\"Compare selected activities to see if they are substantially different.\n",
    "\n",
    "    Substantially different means that all LCIA scores lie within a band of ``band * max_lcia_score``.\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "        ``activities``: List of ``Activity`` objects.\n",
    "        ``lcia_method``: Tuple identifying a ``Method``\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        Nothing, but prints to stdout.\n",
    "\n",
    "    \"\"\"\n",
    "    import bw2calc as bc\n",
    "\n",
    "    activities = [bd.get_activity(obj) for obj in activities]\n",
    "\n",
    "    lca = bc.LCA({a: 1 for a in activities}, lcia_method)\n",
    "    lca.lci()\n",
    "    lca.lcia()\n",
    "\n",
    "    # First pass: Are all scores close?\n",
    "    scores = []\n",
    "\n",
    "    for a in activities:\n",
    "        lca.redo_lcia({a.key: 1})\n",
    "        scores.append(lca.score)\n",
    "\n",
    "    if abs(max(scores) - min(scores)) < band * abs(max(scores)):\n",
    "        print(\"All activities similar\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"Differences observed. LCA scores:\")\n",
    "        for x, y in zip(scores, activities):\n",
    "            print(\"\\t{:5.3f} -> {}\".format(x, y.key))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_leaves(\n",
    "    activity,\n",
    "    lcia_method,\n",
    "    results=None,\n",
    "    lca_obj=None,\n",
    "    amount=1,\n",
    "    total_score=None,\n",
    "    level=0,\n",
    "    max_level=3,\n",
    "    cutoff=2.5e-2,\n",
    "):\n",
    "    \"\"\"Traverse the supply chain of an activity to find leaves - places where the impact of that\n",
    "    component falls below a threshold value.\n",
    "\n",
    "    Returns a list of ``(impact of this activity, amount consumed, Activity instance)`` tuples.\"\"\"\n",
    "    first_level = results is None\n",
    "\n",
    "    activity = bd.get_activity(activity)\n",
    "\n",
    "    if first_level:\n",
    "        level = 0\n",
    "        results = []\n",
    "\n",
    "        lca_obj = bc.LCA({activity: amount}, lcia_method)\n",
    "        lca_obj.lci()\n",
    "        lca_obj.lcia()\n",
    "        total_score = lca_obj.score\n",
    "    else:\n",
    "        lca_obj.redo_lcia({activity.key: amount})\n",
    "\n",
    "        # If this is a leaf, add the leaf and return\n",
    "        if abs(lca_obj.score) <= abs(total_score * cutoff) or level >= max_level:\n",
    "\n",
    "            # Only add leaves with scores that matter\n",
    "            if abs(lca_obj.score) > abs(total_score * 1e-4):\n",
    "                results.append((lca_obj.score, amount, activity))\n",
    "            return results\n",
    "\n",
    "        else:\n",
    "            # Add direct emissions from this demand\n",
    "            direct = (\n",
    "                lca_obj.characterization_matrix\n",
    "                * lca_obj.biosphere_matrix\n",
    "                * lca_obj.demand_array\n",
    "            ).sum()\n",
    "            if abs(direct) >= abs(total_score * 1e-4):\n",
    "                results.append((direct, amount, activity))\n",
    "\n",
    "    for exc in activity.technosphere():\n",
    "        find_leaves(\n",
    "            activity=exc.input,\n",
    "            lcia_method=lcia_method,\n",
    "            results=results,\n",
    "            lca_obj=lca_obj,\n",
    "            amount=amount * exc[\"amount\"],\n",
    "            total_score=total_score,\n",
    "            level=level + 1,\n",
    "            max_level=max_level,\n",
    "            cutoff=cutoff,\n",
    "        )\n",
    "\n",
    "    return sorted(results, reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "def get_cpc(activity):\n",
    "    try:\n",
    "        return next(\n",
    "            cl[1] for cl in activity.get(\"classifications\", []) if cl[0] == \"CPC\"\n",
    "        )\n",
    "    except StopIteration:\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "def get_value_for_cpc(lst, label):\n",
    "    for elem in lst:\n",
    "        if elem[2] == label:\n",
    "            return elem[0]\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def group_leaves(leaves):\n",
    "    \"\"\"Group elements in ``leaves`` by their `CPC (Central Product Classification) <https://unstats.un.org/unsd/classifications/Econ/cpc>`__ code.\n",
    "\n",
    "    Returns a list of ``(fraction of total impact, specific impact, amount, Activity instance)`` tuples.\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for leaf in leaves:\n",
    "        cpc = get_cpc(leaf[2])\n",
    "        if cpc not in results:\n",
    "            results[cpc] = np.zeros((2,))\n",
    "        results[cpc] += np.array(leaf[:2])\n",
    "\n",
    "    return sorted([v.tolist() + [k] for k, v in results.items()], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "def compare_activities_by_grouped_leaves(\n",
    "    activities,\n",
    "    lcia_method,\n",
    "    mode=\"relative\",\n",
    "    max_level=4,\n",
    "    cutoff=0.2,\n",
    "    output_format=\"list\",\n",
    "    str_length=50,\n",
    "):\n",
    "    \"\"\"Compare activities by the impact of their different inputs, aggregated by the product classification of those inputs.\n",
    "\n",
    "    Args:\n",
    "        activities: list of ``Activity`` instances.\n",
    "        lcia_method: tuple. LCIA method to use when traversing supply chain graph.\n",
    "        mode: str. If \"relative\" (default), results are returned as a fraction of total input. Otherwise, results are absolute impact per input exchange.\n",
    "        max_level: int. Maximum level in supply chain to examine.\n",
    "        cutoff: float. Fraction of total impact to cutoff supply chain graph traversal at.\n",
    "        output_format: str. See below.\n",
    "        str_length; int. If ``output_format`` is ``html``, this controls how many characters each column label can have.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: ``activities`` is malformed.\n",
    "\n",
    "    Returns:\n",
    "        Depends on ``output_format``:\n",
    "\n",
    "        * ``list``: Tuple of ``(column labels, data)``\n",
    "        * ``html``: HTML string that will print nicely in Jupyter notebooks.\n",
    "        * ``pandas``: a pandas ``DataFrame``.\n",
    "\n",
    "    \"\"\"\n",
    "    for act in activities:\n",
    "        if not isinstance(act, bd.backends.peewee.proxies.Activity):\n",
    "            raise ValueError(\"`activities` must be an iterable of `Activity` instances\")\n",
    "\n",
    "    objs = [\n",
    "        group_leaves(find_leaves(act, lcia_method, max_level=max_level, cutoff=cutoff))\n",
    "        for act in activities\n",
    "    ]\n",
    "    sorted_keys = sorted(\n",
    "        [\n",
    "            (max([el[0] for obj in objs for el in obj if el[2] == key]), key)\n",
    "            for key in {el[2] for obj in objs for el in obj}\n",
    "        ],\n",
    "        reverse=True,\n",
    "    )\n",
    "    name_common = commonprefix([act[\"name\"] for act in activities])\n",
    "\n",
    "    if \" \" not in name_common:\n",
    "        name_common = \"\"\n",
    "    else:\n",
    "        last_space = len(name_common) - operator.indexOf(reversed(name_common), \" \")\n",
    "        name_common = name_common[:last_space]\n",
    "        print(\"Omitting activity name common prefix: '{}'\".format(name_common))\n",
    "\n",
    "    product_common = commonprefix(\n",
    "        [act.get(\"reference product\", \"\") for act in activities]\n",
    "    )\n",
    "\n",
    "    lca = bc.LCA({act: 1 for act in activities}, lcia_method)\n",
    "    lca.lci()\n",
    "    lca.lcia()\n",
    "\n",
    "    labels = [\n",
    "        \"activity\",\n",
    "        \"product\",\n",
    "        \"location\",\n",
    "        \"unit\",\n",
    "        \"total\",\n",
    "        \"direct emissions\",\n",
    "    ] + [key for _, key in sorted_keys]\n",
    "    data = []\n",
    "    for act, lst in zip(activities, objs):\n",
    "        lca.redo_lcia({act.key: 1})\n",
    "        data.append(\n",
    "            [\n",
    "                act[\"name\"].replace(name_common, \"\"),\n",
    "                act.get(\"reference product\", \"\").replace(product_common, \"\"),\n",
    "                act.get(\"location\", \"\")[:25],\n",
    "                act.get(\"unit\", \"\"),\n",
    "                lca.score,\n",
    "            ]\n",
    "            + [\n",
    "                (\n",
    "                    lca.characterization_matrix\n",
    "                    * lca.biosphere_matrix\n",
    "                    * lca.demand_array\n",
    "                ).sum()\n",
    "            ]\n",
    "            + [get_value_for_cpc(lst, key) for _, key in sorted_keys]\n",
    "        )\n",
    "\n",
    "    data.sort(key=lambda x: x[4], reverse=True)\n",
    "\n",
    "    if mode == \"relative\":\n",
    "        for row in data:\n",
    "            for index, point in enumerate(row[5:]):\n",
    "                row[index + 5] = point / row[4]\n",
    "\n",
    "    if output_format == \"list\":\n",
    "        return labels, data\n",
    "    elif output_format == \"pandas\":\n",
    "        return pd.DataFrame(data, columns=labels)\n",
    "    elif output_format == \"html\":\n",
    "        return tabulate.tabulate(\n",
    "            data,\n",
    "            [x[:str_length] for x in labels],\n",
    "            tablefmt=\"html\",\n",
    "            floatfmt=\".3f\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_activities_multiple_methods(\n",
    "    activities_list, methods, identifier, output_format=\"pandas\", mode=\"absolute\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compares a set of activities by multiple methods, stores each generated dataframe as a variable (the method is the variable name) in a dictionary.\n",
    "\n",
    "    :param activities_list: List of activities to compare\n",
    "    :param methods: List of Brightway Method objects\n",
    "    :param identifier: A string used in defining the variable names to better identify comparisons (e.g. sector name).\n",
    "    :param output_format: Output format for the comparison (default: 'pandas')\n",
    "    :param mode: Mode for the comparison (default: 'absolute'; others: 'relative')\n",
    "    :return: Dictionary of resulting dataframes from the comparisons\n",
    "    \"\"\"\n",
    "    dataframes_dict = {}\n",
    "\n",
    "    for method_key, method_details in methods.items():\n",
    "        result = compare_activities_by_grouped_leaves(\n",
    "            activities_list,\n",
    "            method_details[\"object\"].name,\n",
    "            output_format=output_format,\n",
    "            mode=mode,\n",
    "        )\n",
    "\n",
    "        # Create a variable name using the method name tuple and identifier\n",
    "        method_name = method_details[\"object\"].name[2].replace(\" \", \"_\").lower()\n",
    "        var_name = f\"{identifier}_{method_name}\"\n",
    "\n",
    "        # add two columns method and method unit to the df\n",
    "        result[\"method\"] = str(method_details[\"object\"].name[2])\n",
    "        result[\"method unit\"] = str(method_details[\"object\"].metadata[\"unit\"])\n",
    "\n",
    "        # order the columns after column unit\n",
    "        cols = list(result.columns)\n",
    "        unit_index = cols.index(\"unit\")\n",
    "        cols.insert(unit_index + 1, cols.pop(cols.index(\"method\")))\n",
    "        cols.insert(unit_index + 2, cols.pop(cols.index(\"method unit\")))\n",
    "        result = result[cols]\n",
    "\n",
    "        # Order the rows based on 'activity' and 'location' columns\n",
    "        result = result.sort_values([\"activity\", \"location\"])\n",
    "\n",
    "        # Reset the index numbering\n",
    "        result = result.reset_index(drop=True)\n",
    "\n",
    "        # Store the result in the dictionary\n",
    "        dataframes_dict[var_name] = result\n",
    "\n",
    "    return dataframes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_inputs_to_other_column(dataframes_dict, cutoff=0.01):\n",
    "    \"\"\"\n",
    "    Aggregate values into a new 'other' column for those contributing less than or equal to the cutoff value to the 'total' column value.\n",
    "    Set the aggregated values to zero in their original columns.\n",
    "    Remove any columns that end up containing only zeros.\n",
    "\n",
    "    :param dataframes_dict: the dictionary\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    processed_dict = {}\n",
    "\n",
    "    for key, df in dataframes_dict.items():\n",
    "        # Identify the 'total' column\n",
    "        total_col_index = df.columns.get_loc(\"total\")\n",
    "\n",
    "        # Separate string and numeric columns\n",
    "        string_cols = df.iloc[:, :total_col_index]\n",
    "        numeric_cols = df.iloc[:, total_col_index:]\n",
    "        numeric_cols = numeric_cols.astype(float)\n",
    "\n",
    "        # Calculate the threshold for each row (1% of total)\n",
    "        threshold = numeric_cols[\"total\"] * cutoff\n",
    "\n",
    "        # Create 'other' column\n",
    "        numeric_cols[\"other\"] = 0.0\n",
    "\n",
    "        # Process each numeric column (except 'total' and 'other')\n",
    "        for col in numeric_cols.columns[1:-1]:  # Skip 'total' and 'other'\n",
    "            # Identify values less than the threshold\n",
    "            mask = (\n",
    "                abs(numeric_cols[col]) < threshold\n",
    "            )  # abs() to include negative contributions\n",
    "\n",
    "            # Add these values to 'other'\n",
    "            numeric_cols.loc[mask, \"other\"] += numeric_cols.loc[mask, col]\n",
    "\n",
    "            # Set these values to zero in the original column\n",
    "            numeric_cols.loc[mask, col] = 0\n",
    "\n",
    "        # Remove columns with all zeros (except 'total' and 'other')\n",
    "        cols_to_keep = [\"total\"] + [\n",
    "            col\n",
    "            for col in numeric_cols.columns[1:-1]\n",
    "            if not (numeric_cols[col] == 0).all()\n",
    "        ]\n",
    "        cols_to_keep.append(\"other\")\n",
    "\n",
    "        numeric_cols = numeric_cols[cols_to_keep]\n",
    "\n",
    "        # Combine string and processed numeric columns\n",
    "        processed_df = pd.concat([string_cols, numeric_cols], axis=1)\n",
    "\n",
    "        # Sort columns by total\n",
    "        processed_df = processed_df.sort_values(\"total\", ascending=False)\n",
    "\n",
    "        # Store the processed DataFrame in the result dictionary\n",
    "        processed_dict[key] = processed_df\n",
    "\n",
    "    return processed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_lca_scores(main_dict, method_dict):\n",
    "    '''\n",
    "    Generates the LCA score tables for activity list of each sector.\n",
    "    The tables contain total scores and cpc input contributions.\n",
    "    This is done by each method defined in the method dictionary.\n",
    "\n",
    "    :param main_dict: dictionary which is returned by process_yaml_files function\n",
    "    :param method_dict: dictionary which is created with MethodFinder class\n",
    "\n",
    "    It returns the main dictionary updated as scores dictionary which also holds the former information for each sector.\n",
    "    The LCA scores are stored by method name in the respective sector dictionary within the main dictionary.\n",
    "    '''\n",
    "\n",
    "    # Initialize scores_dict as a copy of main_dict\n",
    "    scores_dict = main_dict.copy()\n",
    "\n",
    "    # Loop through each sector in main_dict\n",
    "    for sector in scores_dict.keys():\n",
    "        # Extract activities for the current sector\n",
    "        sector_activities = scores_dict[sector]['activities']\n",
    "        \n",
    "        # Calculate LCA scores using the specified method\n",
    "        lca_scores = compare_activities_multiple_methods(\n",
    "            activities_list=sector_activities,\n",
    "            methods=method_dict,\n",
    "            identifier=sector,\n",
    "            mode='absolute'\n",
    "        )\n",
    "        \n",
    "        # Apply the small_inputs_to_other_column function with the cutoff value\n",
    "        lca_scores = small_inputs_to_other_column(lca_scores, cutoff=0.02)\n",
    "        \n",
    "        # Save the LCA scores to the scores_dict\n",
    "        scores_dict[sector]['lca_scores'] = lca_scores\n",
    "\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitting activity name common prefix: 'cement production, '\n",
      "Omitting activity name common prefix: 'cement production, '\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n"
     ]
    }
   ],
   "source": [
    "scores_dict = sector_lca_scores(dictionary_one, method_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitting activity name common prefix: 'cement production, '\n",
      "Omitting activity name common prefix: 'cement production, '\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n",
      "Omitting activity name common prefix: 'steel production, electric, '\n"
     ]
    }
   ],
   "source": [
    "scores_dict_cutoff = sector_lca_scores(dictionary_one, method_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "index_pos=dopo.sector_lca_scores_to_excel_and_column_positions(scores_dict, 'test_dopo_unnamed_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cement_global_warming_potential_(gwp100)': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Cement_cumulative_energy_demand_-_non-renewable_energy_resources': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Steel_global_warming_potential_(gwp100)': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14},\n",
       " 'Steel_cumulative_energy_demand_-_non-renewable_energy_resources': {'total': 7,\n",
       "  'rank': 8,\n",
       "  'mean': 9,\n",
       "  '2std_abv': 10,\n",
       "  '2std_blw': 11,\n",
       "  'q1': 12,\n",
       "  'q3': 13,\n",
       "  'method': 5,\n",
       "  'method unit': 6,\n",
       "  'first_input': 14}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dopo.sector_lca_scores_to_excel_and_column_positions(scores_dict, 'test_dopo_unnamed_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dopo.plots_in_xcl\n",
    "\n",
    "\n",
    "current_row=dopo.plots_in_xcl.dot_plots_xcl('test_dopo_3.xlsx', index_pos) #update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No matching key found for worksheet 'Steel_charts'. Skipping...\n",
      "Warning: No matching key found for worksheet 'Cement_charts'. Skipping...\n"
     ]
    }
   ],
   "source": [
    "dopo.plots_in_xcl.stacked_bars_xcl('test_dopo_3.xlsx', index_pos, current_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparison of databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'relative_changes_db'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dopo\u001b[38;5;241m.\u001b[39mrelative_changes_db\u001b[38;5;241m.\u001b[39mrelative_changes_db(ecoinvent_dict, premise_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpart2_test_dopo_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'relative_changes_db'"
     ]
    }
   ],
   "source": [
    "dopo.relative_changes_db.relative_changes_db(ecoinvent_dict, premise_dict, 'part2_test_dopo_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dopo.plots_in_xcl.barchart_compare_db_xcl('part2_test_dopo_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "premise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
